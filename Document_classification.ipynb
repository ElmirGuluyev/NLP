{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Purpose and Introduction\n",
        "\n",
        "The purpose of this code is to build document classification model using four different approaches - bag-of-words with Naive Bayes classifier and BiLSTM model with Elmo and BERT elbedding layer. The document classification is an important task in natural language processing as it allows to automatically assigning topics to news articles, books, social media post, etc. We decided to work with BBC dataset that has collection of news articles and classes. This dataset has five categories, however for the purpose of our project, we will be using only three"
      ],
      "metadata": {
        "id": "bczfsyNKqHRs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Importing Dataset"
      ],
      "metadata": {
        "id": "PJ0aF8QJr4oe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Python code uses the Pandas library to load a dataset in CSV format from a URL, specifically the BBC news dataset. The loaded dataset is stored in a Pandas DataFrame called df. The BBC dataset contains news articles published by the BBC news website, along with their corresponding category labels. The dataset consists of 2,225 documents in five categories: Business, Entertainment, Politics, Sport, and Tech.\n"
      ],
      "metadata": {
        "id": "dk42Jd-1qTGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "url = 'https://storage.googleapis.com/dataset-uploader/bbc/bbc-text.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Print the first few rows of the dataset\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dUpOpOCOs3z",
        "outputId": "16aed907-04f8-4264-94f7-4b76c2262f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        category                                               text\n",
            "0           tech  tv future in the hands of viewers with home th...\n",
            "1       business  worldcom boss  left books alone  former worldc...\n",
            "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
            "3          sport  yeading face newcastle in fa cup premiership s...\n",
            "4  entertainment  ocean s twelve raids box office ocean s twelve...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the unique categories in the dataset\n",
        "print(df['category'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sNnvZGLPEbn",
        "outputId": "84a709f5-329b-4e5a-f5b9-c80af77b674f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tech' 'business' 'sport' 'entertainment' 'politics']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Python code calculates the average length of the news articles in the BBC dataset"
      ],
      "metadata": {
        "id": "tv92nnUorMio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "d = []\n",
        "for t in df['text']:\n",
        "  l = len(t)\n",
        "  d.append(l)\n",
        "print( sum(d) / len(d))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDiRfLK-Pop2",
        "outputId": "3e9f3f7b-1fe7-4fb6-e481-d07b2f7d9166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2262.936179775281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DJBAH0sQd5t",
        "outputId": "8e0d0e95-ca53-47a6-e1a3-df18533260c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2225"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code first imports the NLTK library, which provides tools for working with natural language text in Python. Next, we download the ‘punkt’ which is pre-trained tokenizer. We use this tokenizer for our word_tokenize() function. Next, we create new column called ‘tokenized_text” which will store the tokenized version of each article. Finally, the code applies word_tokenize() function to text colum. This function tokenizes each news article into a list of words, and the resulting list is stored in the tokenized_text column of the same row."
      ],
      "metadata": {
        "id": "5E1y2dPTrSwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "df[\"tokenized_text\"] = df[\"text\"].apply(nltk.word_tokenize)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w6IGkLOTRMs",
        "outputId": "007f31cf-e1c0-47fd-c00c-d69be9802cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use train_test_split function from the sklearn.model_selection module to split your dataset into a training set and a test set. The test_size parameter is set to 0.2, meaning that 20% of the dataset will be reserved for the test set and the remaining 80% will be used for the training set. The random_state parameter is set to 42, which ensures that the random selection of data points is consistent across multiple runs."
      ],
      "metadata": {
        "id": "6IbZy0cArYdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the dataset into testing and training data sets\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "1VWPpGWRQ3d7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet is a function called prep, which takes a Pandas DataFrame df and a column name column as input. The purpose of this function is to preprocess the text data in the specified column by performing the following steps:\n",
        "Download necessary NLTK resources: It downloads the NLTK stopword list and WordNet lemmatizer data, which are used for preprocessing the text data.\n",
        "Remove stopwords: It creates a set of English stopwords using the NLTK library and removes them from the text. Stopwords are common words that do not carry significant meaning and are often removed from the text data to reduce noise and improve computational efficiency.\n",
        "Lemmatize words: The function applies the WordNetLemmatizer from the NLTK library to convert words in the text to their base or dictionary form, known as lemmas. This process helps in reducing the dimensionality of the data and grouping similar words together.\n",
        "Convert words to lowercase: It converts all words in the text to lowercase. This step is performed to ensure that the text data is consistent and not affected by differences in letter case.\n",
        "Remove punctuation: The function uses a regular expression to remove any punctuation marks from the words in the text. Removing punctuation marks helps in simplifying the text and reducing noise in the data.\n"
      ],
      "metadata": {
        "id": "L3MumW2AsVOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Doing the necessary pre-processing\n",
        "\n",
        "def prep(df, column):\n",
        "    stop_words = set(stopwords.words('english')) # creating a set of English stop words\n",
        "    lemmatizer = WordNetLemmatizer() # creating a lemmatizer object\n",
        "    df[column] = df[column].apply(lambda x: [word for word in x if word not in stop_words]) # remove stopwords\n",
        "    df[column] = df[column].apply(lambda x: [lemmatizer.lemmatize(word) for word in x]) # lemmatizing each list\n",
        "    df[column] = df[column].apply(lambda x: [word.lower() for word in x]) # converting each word to lowercase\n",
        "    df[column] = df[column].apply(lambda x: [re.sub(r'[^\\w\\s]','', word) for word in x]) # remove punctuation\n",
        "    return df"
      ],
      "metadata": {
        "id": "HVYAGgvHUnqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e379add3-45ab-4ee5-f87f-051e916d8532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prep(df, 'tokenized_text')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "N1RG6TtOZ0ho",
        "outputId": "a8d30872-306c-4fa5-b630-3e4080d5d0f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           category                                               text  \\\n",
              "0              tech  tv future in the hands of viewers with home th...   \n",
              "1          business  worldcom boss  left books alone  former worldc...   \n",
              "2             sport  tigers wary of farrell  gamble  leicester say ...   \n",
              "3             sport  yeading face newcastle in fa cup premiership s...   \n",
              "4     entertainment  ocean s twelve raids box office ocean s twelve...   \n",
              "...             ...                                                ...   \n",
              "2220       business  cars pull down us retail figures us retail sal...   \n",
              "2221       politics  kilroy unveils immigration policy ex-chatshow ...   \n",
              "2222  entertainment  rem announce new glasgow concert us band rem h...   \n",
              "2223       politics  how political squabbles snowball it s become c...   \n",
              "2224          sport  souness delight at euro progress boss graeme s...   \n",
              "\n",
              "                                         tokenized_text  \n",
              "0     [tv, future, hand, viewer, home, theatre, syst...  \n",
              "1     [worldcom, bos, left, book, alone, former, wor...  \n",
              "2     [tiger, wary, farrell, gamble, leicester, say,...  \n",
              "3     [yeading, face, newcastle, fa, cup, premiershi...  \n",
              "4     [ocean, twelve, raid, box, office, ocean, twel...  \n",
              "...                                                 ...  \n",
              "2220  [car, pull, u, retail, figure, u, retail, sale...  \n",
              "2221  [kilroy, unveils, immigration, policy, exchats...  \n",
              "2222  [rem, announce, new, glasgow, concert, u, band...  \n",
              "2223  [political, squabble, snowball, become, common...  \n",
              "2224  [souness, delight, euro, progress, bos, graeme...  \n",
              "\n",
              "[2225 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ae50ceb-549a-4c05-85f5-9af9c6a5457b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "      <th>tokenized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "      <td>[tv, future, hand, viewer, home, theatre, syst...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "      <td>[worldcom, bos, left, book, alone, former, wor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "      <td>[tiger, wary, farrell, gamble, leicester, say,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sport</td>\n",
              "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
              "      <td>[yeading, face, newcastle, fa, cup, premiershi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
              "      <td>[ocean, twelve, raid, box, office, ocean, twel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2220</th>\n",
              "      <td>business</td>\n",
              "      <td>cars pull down us retail figures us retail sal...</td>\n",
              "      <td>[car, pull, u, retail, figure, u, retail, sale...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2221</th>\n",
              "      <td>politics</td>\n",
              "      <td>kilroy unveils immigration policy ex-chatshow ...</td>\n",
              "      <td>[kilroy, unveils, immigration, policy, exchats...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2222</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>rem announce new glasgow concert us band rem h...</td>\n",
              "      <td>[rem, announce, new, glasgow, concert, u, band...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2223</th>\n",
              "      <td>politics</td>\n",
              "      <td>how political squabbles snowball it s become c...</td>\n",
              "      <td>[political, squabble, snowball, become, common...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2224</th>\n",
              "      <td>sport</td>\n",
              "      <td>souness delight at euro progress boss graeme s...</td>\n",
              "      <td>[souness, delight, euro, progress, bos, graeme...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2225 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ae50ceb-549a-4c05-85f5-9af9c6a5457b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0ae50ceb-549a-4c05-85f5-9af9c6a5457b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0ae50ceb-549a-4c05-85f5-9af9c6a5457b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8TaUNZbTY64v",
        "outputId": "0f7aa0c3-d62d-4837-8c28-ce6558d3abef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        category                                               text  \\\n",
              "0           tech  tv future in the hands of viewers with home th...   \n",
              "1       business  worldcom boss  left books alone  former worldc...   \n",
              "2          sport  tigers wary of farrell  gamble  leicester say ...   \n",
              "3          sport  yeading face newcastle in fa cup premiership s...   \n",
              "4  entertainment  ocean s twelve raids box office ocean s twelve...   \n",
              "\n",
              "                                      tokenized_text  \n",
              "0  [tv, future, hand, viewer, home, theatre, syst...  \n",
              "1  [worldcom, bos, left, book, alone, former, wor...  \n",
              "2  [tiger, wary, farrell, gamble, leicester, say,...  \n",
              "3  [yeading, face, newcastle, fa, cup, premiershi...  \n",
              "4  [ocean, twelve, raid, box, office, ocean, twel...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7348a33e-a76d-4b26-86c6-dfd54d57c5ba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "      <th>tokenized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "      <td>[tv, future, hand, viewer, home, theatre, syst...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "      <td>[worldcom, bos, left, book, alone, former, wor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "      <td>[tiger, wary, farrell, gamble, leicester, say,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sport</td>\n",
              "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
              "      <td>[yeading, face, newcastle, fa, cup, premiershi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
              "      <td>[ocean, twelve, raid, box, office, ocean, twel...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7348a33e-a76d-4b26-86c6-dfd54d57c5ba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7348a33e-a76d-4b26-86c6-dfd54d57c5ba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7348a33e-a76d-4b26-86c6-dfd54d57c5ba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes with Bag-of-Words Feature"
      ],
      "metadata": {
        "id": "0X7t-gTZbnJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Naive Bayes classifier (with BOW approach) we slightly altered our pre-processing function. When dealing with stop words, we also accounted for negation words and did not remove them. Negations carry important sentiment and therefore, it is essential to preserve them."
      ],
      "metadata": {
        "id": "LZlGeVFjYeMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pre-processing for bag of words approach\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "\n",
        "def prep_bow(df, column):\n",
        "    stop_words = set(stopwords.words('english')) - {'not', 'no', 'nor', 'neither'} # creating a set of English stop words excluding negation words\n",
        "    lemmatizer = WordNetLemmatizer() # creating a lemmatizer object\n",
        "    df[column] = df[column].apply(lambda x: [word for word in x if word not in stop_words]) # remove stopwords\n",
        "    df[column] = df[column].apply(lambda x: [lemmatizer.lemmatize(word) for word in x]) # lemmatizing each list\n",
        "    df[column] = df[column].apply(lambda x: [word.lower() for word in x]) # converting each word to lowercase\n",
        "    df[column] = df[column].apply(lambda x: [re.sub(r'[^\\w\\s]','', word) for word in x]) # remove punctuation\n",
        "    return df"
      ],
      "metadata": {
        "id": "_TT7FjCBixMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prep_bow(df, 'tokenized_text')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "RkewN7x4i_R5",
        "outputId": "f3d05df2-4a49-4e26-fb2f-0899d1b287bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           category                                               text  \\\n",
              "0              tech  tv future in the hands of viewers with home th...   \n",
              "1          business  worldcom boss  left books alone  former worldc...   \n",
              "2             sport  tigers wary of farrell  gamble  leicester say ...   \n",
              "3             sport  yeading face newcastle in fa cup premiership s...   \n",
              "4     entertainment  ocean s twelve raids box office ocean s twelve...   \n",
              "...             ...                                                ...   \n",
              "2220       business  cars pull down us retail figures us retail sal...   \n",
              "2221       politics  kilroy unveils immigration policy ex-chatshow ...   \n",
              "2222  entertainment  rem announce new glasgow concert us band rem h...   \n",
              "2223       politics  how political squabbles snowball it s become c...   \n",
              "2224          sport  souness delight at euro progress boss graeme s...   \n",
              "\n",
              "                                         tokenized_text  \n",
              "0     [tv, future, hand, viewer, home, theatre, syst...  \n",
              "1     [worldcom, bos, left, book, alone, former, wor...  \n",
              "2     [tiger, wary, farrell, gamble, leicester, say,...  \n",
              "3     [yeading, face, newcastle, fa, cup, premiershi...  \n",
              "4     [ocean, twelve, raid, box, office, ocean, twel...  \n",
              "...                                                 ...  \n",
              "2220  [car, pull, u, retail, figure, u, retail, sale...  \n",
              "2221  [kilroy, unveils, immigration, policy, exchats...  \n",
              "2222  [rem, announce, new, glasgow, concert, u, band...  \n",
              "2223  [political, squabble, snowball, become, common...  \n",
              "2224  [souness, delight, euro, progress, bos, graeme...  \n",
              "\n",
              "[2225 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ceb640d-6700-4713-bf18-f1905b918cd2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "      <th>tokenized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "      <td>[tv, future, hand, viewer, home, theatre, syst...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "      <td>[worldcom, bos, left, book, alone, former, wor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "      <td>[tiger, wary, farrell, gamble, leicester, say,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sport</td>\n",
              "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
              "      <td>[yeading, face, newcastle, fa, cup, premiershi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
              "      <td>[ocean, twelve, raid, box, office, ocean, twel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2220</th>\n",
              "      <td>business</td>\n",
              "      <td>cars pull down us retail figures us retail sal...</td>\n",
              "      <td>[car, pull, u, retail, figure, u, retail, sale...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2221</th>\n",
              "      <td>politics</td>\n",
              "      <td>kilroy unveils immigration policy ex-chatshow ...</td>\n",
              "      <td>[kilroy, unveils, immigration, policy, exchats...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2222</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>rem announce new glasgow concert us band rem h...</td>\n",
              "      <td>[rem, announce, new, glasgow, concert, u, band...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2223</th>\n",
              "      <td>politics</td>\n",
              "      <td>how political squabbles snowball it s become c...</td>\n",
              "      <td>[political, squabble, snowball, become, common...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2224</th>\n",
              "      <td>sport</td>\n",
              "      <td>souness delight at euro progress boss graeme s...</td>\n",
              "      <td>[souness, delight, euro, progress, bos, graeme...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2225 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ceb640d-6700-4713-bf18-f1905b918cd2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ceb640d-6700-4713-bf18-f1905b918cd2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ceb640d-6700-4713-bf18-f1905b918cd2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Correcting the order for easy use\n",
        "docs = df[[\"tokenized_text\",\"category\"]]\n",
        "docs = list(df[['tokenized_text', 'category']].itertuples(index=False, name=None))"
      ],
      "metadata": {
        "id": "SeU59gXQbpk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1GCbIQScrSw",
        "outputId": "d00d6c7a-7af3-4d50-912b-e1c1f3791f02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2225"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we create a baseline Bag-of-Words (BOW) model for text classification. First we import all necessary libraries. As step two we are shuffling the dataset so its randomly distributed before splitting in into training and testing sets. Step three: we create a a list of all words: all_words_list is a list of all words in the dataset. A frequency distribution of these words is calculated using nltk.FreqDist(). After that we selected 2000 most common words and stored them in word_features. Next, we defined document_feature() function which takes  a document and a list of word features as input, and it returns a dictionary with keys as 'V_word' and values as True or False, indicating whether the word is present in the document. Lastly, we generate feature sets: The featuresets variable is created by applying the document_features() function to each document in the docs list. "
      ],
      "metadata": {
        "id": "2vfvMaHcYyJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Baseline BOW\n",
        "import nltk\n",
        "import random\n",
        "\n",
        "random.shuffle(docs)\n",
        "\n",
        "all_words_list = [word for (sent,cat) in docs for word in sent]\n",
        "all_words = nltk.FreqDist(all_words_list)\n",
        "\n",
        "#Getting the most common 2000 words\n",
        "word_items = all_words.most_common(2000)\n",
        "word_features = [word for (word,count) in word_items]\n",
        "\n",
        "def document_features(document, word_features):\n",
        "    document_words = set(document)\n",
        "    features = {}\n",
        "    for word in word_features:\n",
        "        features['V_{}'.format(word)] = (word in document_words)\n",
        "    return features\n",
        "\n",
        "#get features sets for a document, including keyword features and category feature\n",
        "featuresets = [(document_features(d, word_features), c) for (d, c) in docs]"
      ],
      "metadata": {
        "id": "eBhTqF43bmNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training using naive Baysian classifier, training set is approximately 90% of data\n",
        "train_set, test_set = featuresets[1000:], featuresets[:1000]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "# evaluate the accuracy of the classifier\n",
        "nltk.classify.accuracy(classifier, test_set)\n",
        "\n",
        "# the accuracy result may vary since we randomized the documents"
      ],
      "metadata": {
        "id": "kANrFNHGcMJR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b40821ec-b082-4686-eced-bf2fa9c6f014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.971"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "\n",
        "#Get the true labels and predicted labels for the test set\n",
        "true_labels = [cat for (_, cat) in test_set]\n",
        "predicted_labels = [classifier.classify(features) for (features, _) in test_set]\n",
        "\n",
        "#Calculate precision, recall, and F1 score for each category\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(\n",
        "    true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "#Print the results\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 score:\", f1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WIQwLLahoC7",
        "outputId": "0406de7b-ec0f-40bb-c388-701a699b28eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9712197358052809\n",
            "Recall: 0.971\n",
            "F1 score: 0.9710097885105838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is creating a text classification model using the bag-of-words approach and a Linear Support Vector Machine (SVM) classifier. The goal is to classify documents into categories based on the words they contain.\n",
        "First, the documents are shuffled randomly to ensure a good distribution of categories in the training and testing datasets.\n",
        "Then, a list of the most common 2000 words across all documents is created, which will serve as features for the classification model.\n",
        "A function called document_features is defined to create a dictionary of word features for each document. This function checks if each word from the list of common words is present in a given document, and records this information as a feature.\n",
        "The document_features function is applied to all documents to create a feature set, which is a collection of document features and their corresponding categories.\n",
        "The feature set is split into a training set (200 documents) and a testing set (the remaining documents) to evaluate the performance of the model.\n",
        "A Linear SVM classifier is trained on the training set using the SklearnClassifier class from nltk, which is a wrapper around scikit-learn's LinearSVC class.\n",
        "Finally, the accuracy of the classifier is evaluated on the test set using nltk's classify.accuracy function, and the accuracy is printed out.\n",
        "In summary, this code demonstrates how to create a simple text classification model by representing documents as bags of words and using a Linear SVM classifier to predict the categories of the documents. The accuracy of the model will depend on the dataset and the features used for classification.\n"
      ],
      "metadata": {
        "id": "cci53QJYY5yZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from sklearn.svm import LinearSVC\n",
        "from nltk.classify.scikitlearn import SklearnClassifier\n",
        "\n",
        "# Shuffle the documents\n",
        "random.shuffle(docs)\n",
        "\n",
        "# Create bag of words feature set\n",
        "all_words_list = [word for (sent,cat) in docs for word in sent]\n",
        "all_words = nltk.FreqDist(all_words_list)\n",
        "word_items = all_words.most_common(2000)\n",
        "word_features = [word for (word,count) in word_items]\n",
        "def document_features(document, word_features):\n",
        "    document_words = set(document)\n",
        "    features = {}\n",
        "    for word in word_features:\n",
        "        features['V_{}'.format(word)] = (word in document_words)\n",
        "    return features\n",
        "featuresets = [(document_features(d, word_features), c) for (d, c) in docs]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_set, test_set = featuresets[200:], featuresets[:200]\n",
        "\n",
        "# Train the SVM classifier\n",
        "svm_classifier = SklearnClassifier(LinearSVC())\n",
        "svm_classifier.train(train_set)\n",
        "\n",
        "# Evaluate the accuracy of the classifier\n",
        "accuracy = nltk.classify.accuracy(svm_classifier, test_set)\n",
        "print('Accuracy:', accuracy)"
      ],
      "metadata": {
        "id": "SXjfk4Q4lSdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eb5af3b-b44e-4ea5-b94b-d7411849cbca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "# Get the true labels and predicted labels\n",
        "true_labels = [cat for (doc, cat) in test_set]\n",
        "predicted_labels = [svm_classifier.classify(doc) for (doc, cat) in test_set]\n",
        "\n",
        "# Calculate the precision, recall, and F1 score\n",
        "precision = metrics.precision_score(true_labels, predicted_labels, average='weighted')\n",
        "recall = metrics.recall_score(true_labels, predicted_labels, average='weighted')\n",
        "f1_score = metrics.f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print the results\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('F1 Score:', f1_score)"
      ],
      "metadata": {
        "id": "oKDTC0mQlmy4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09979917-cdf5-4e60-9560-922c86163c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.98\n",
            "Recall: 0.98\n",
            "F1 Score: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BiLSTM model using Elmo Embedding**"
      ],
      "metadata": {
        "id": "4gaeVI95nQ61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask = (df['category'] == 'politics') | (df['category'] == 'tech') | (df['category'] == 'sport')\n",
        "df = df[mask]"
      ],
      "metadata": {
        "id": "5GU3gNSHi_t5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[:300].copy()"
      ],
      "metadata": {
        "id": "J3108gmwu5Wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rLBSEnz9iwMo",
        "outputId": "995e2cdd-2c79-4475-b61a-13bad1111a5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   category                                               text  \\\n",
              "0      tech  tv future in the hands of viewers with home th...   \n",
              "2     sport  tigers wary of farrell  gamble  leicester say ...   \n",
              "3     sport  yeading face newcastle in fa cup premiership s...   \n",
              "5  politics  howard hits back at mongrel jibe michael howar...   \n",
              "6  politics  blair prepares to name poll date tony blair is...   \n",
              "\n",
              "                                      tokenized_text  \n",
              "0  [tv, future, hand, viewer, home, theatre, syst...  \n",
              "2  [tiger, wary, farrell, gamble, leicester, say,...  \n",
              "3  [yeading, face, newcastle, fa, cup, premiershi...  \n",
              "5  [howard, hit, back, mongrel, jibe, michael, ho...  \n",
              "6  [blair, prepares, name, poll, date, tony, blai...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e39f0ea3-654f-40f1-b1f8-11094ad5b563\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "      <th>tokenized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "      <td>[tv, future, hand, viewer, home, theatre, syst...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "      <td>[tiger, wary, farrell, gamble, leicester, say,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sport</td>\n",
              "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
              "      <td>[yeading, face, newcastle, fa, cup, premiershi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>politics</td>\n",
              "      <td>howard hits back at mongrel jibe michael howar...</td>\n",
              "      <td>[howard, hit, back, mongrel, jibe, michael, ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>politics</td>\n",
              "      <td>blair prepares to name poll date tony blair is...</td>\n",
              "      <td>[blair, prepares, name, poll, date, tony, blai...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e39f0ea3-654f-40f1-b1f8-11094ad5b563')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e39f0ea3-654f-40f1-b1f8-11094ad5b563 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e39f0ea3-654f-40f1-b1f8-11094ad5b563');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing neccassary modules\n",
        "# ! pip install \"tensorflow>=1.7.0\"\n",
        "# ! pip install tensorflow-hub\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub"
      ],
      "metadata": {
        "id": "0_oP5hNbpG-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is importing a pre-trained machine learning model called ELMo, which can be used for processing natural language text. ELMo stands for \"Embeddings from Language Models\", and it's a deep neural network that can generate vector representations of words and sentences.\n",
        "To use this pre-trained ELMo model, the code first disables a feature called \"eager execution\" in TensorFlow, which is a way to run TensorFlow operations immediately rather than creating a computational graph. Next, it clears the current backend session to reset the TensorFlow environment.\n",
        "Then, the code initializes all the global variables in the TensorFlow graph to prepare for using the ELMo module. Finally, the code imports the ELMo model from the TensorFlow Hub, using a specific URL that points to version 2 of the ELMo model. The trainable=True parameter means that the weights of the ELMo model can be fine-tuned during training, allowing the model to learn from new data."
      ],
      "metadata": {
        "id": "8RzAYpvHZEbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing pre-trained Elmo model\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "tf.keras.backend.clear_session()\n",
        "init = tf.compat.v1.global_variables_initializer()\n",
        "\n",
        "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)"
      ],
      "metadata": {
        "id": "e5ALAnE3pHzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a function called embedding_elmo that can convert text input into ELMo embeddings. ELMo stands for \"Embeddings from Language Models,\" and it's a type of machine learning model that can create numerical representations of words and sentences.\n",
        "The function takes a text input x as its input. The elmo() function from TensorFlow Hub is used to process the input text and generate ELMo embeddings. The elmo() function takes a list of strings as input and returns the ELMo embeddings of each string as a tensor.\n",
        "The next few lines of the function initialize the TensorFlow graph and session, which are necessary for using the ELMo module. The run() function is called twice to initialize the global variables and vocabulary lookup tables used by the ELMo module.\n",
        "Finally, the reduce_mean() function is called to compute the average of the ELMo embeddings across the second dimension of the tensor. This returns a tensor with shape (batch_size, embedding_size), where batch_size is the number of input strings and embedding_size is the size of the ELMo embeddings. The function then returns this tensor as the output of the function.\n",
        "Overall, this function is a useful tool for converting raw text into a format that can be used by machine learning models, especially those that are designed for natural language processing tasks like text classification or sentiment analysis.\n",
        "Regenerate response\n"
      ],
      "metadata": {
        "id": "Z9G6R8GJZFqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def embedding_elmo(x):\n",
        "  embeddings = elmo(x.tolist(), signature=\"default\", as_dict=True)[\"elmo\"]\n",
        "  start = tf.compat.v1.global_variables_initializer()\n",
        "  with tf.compat.v1.Session() as sess:\n",
        "    sess.run(start)\n",
        "    sess.run(tf.compat.v1.tables_initializer())\n",
        "    # return average of ELMo features\n",
        "    return sess.run(tf.reduce_mean(embeddings,1))"
      ],
      "metadata": {
        "id": "9Wt_pGw0pbjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code uses the train_test_split function from the sklearn.model_selection library to split our dataset df into separate training and testing subsets. The purpose of this split is to create a way to evaluate our machine learning model's performance on unseen data.\n",
        "We decided to split the data into a training set and a testing set using a 80/20 split. This means that 80% of the data will be used for training the model, and 20% will be used for testing. We also set the random_state parameter to 42, which means that we will get the same split every time we run the code.\n",
        "The output of the train_test_split function is a tuple of two dataframes: train and test. The train dataframe contains a subset of the original dataset that we will use to train our machine learning model. The test dataframe contains a subset of the data that we will use to evaluate the model's performance."
      ],
      "metadata": {
        "id": "i7dBy4lEZQ7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the dataset into testing and training data sets\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "4MjjtsndqfVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['category'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC21JWIqmGOg",
        "outputId": "bb9a16e2-df6a-4536-e800-57fcb944e91b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['tech', 'sport', 'politics'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_categories = train['category'].unique().tolist()\n",
        "print(unique_categories)"
      ],
      "metadata": {
        "id": "AeFOuGaRuBrN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0fcd911-3b9e-4901-9d5b-4b95bd28e85d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tech', 'sport', 'politics']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is dividing the train and test dataframes into smaller batches of size 20 using a list comprehension. The smaller batches are created by iterating over the rows of the dataframes with a step size of 20 and selecting 20 rows starting from the current row index. The resulting batches are stored in two separate lists called list_tr and list_te."
      ],
      "metadata": {
        "id": "I5gV4DKDZPu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the train and test datasets into smaller batches of size 20\n",
        "list_tr = [train[i:i + 20] for i in range(0,train.shape[0], 20)]\n",
        "list_te = [test[i:i + 20] for i in range(0,test.shape[0], 20)]"
      ],
      "metadata": {
        "id": "vPb3g-8dp___"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The embedding_elmo() function that we defined earlier is called for each batch of data, passing in the text data for each row of the batch. This function converts each text input into a tensor of ELMo embeddings.\n",
        "The resulting ELMo embeddings for each batch of data are stored in two separate lists called elmo_train and elmo_test. These lists will be used as inputs to our machine learning model to train and test its performance."
      ],
      "metadata": {
        "id": "ohhgWwEFZX6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting ELMo embeddings\n",
        "elmo_train = [embedding_elmo(x['text']) for x in list_tr]\n",
        "elmo_test = [embedding_elmo(x['text']) for x in list_te]"
      ],
      "metadata": {
        "id": "kSNTdbU4qCe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Concatenating the arrays into one\n",
        "elmo_train_new = np.concatenate(elmo_train, axis = 0)\n",
        "elmo_test_new = np.concatenate(elmo_test, axis = 0)"
      ],
      "metadata": {
        "id": "r-WPKlrhqE3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elmo_train_new.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6LkJi_iv7mY",
        "outputId": "618c126b-4838-471d-c987-0a4946b8a60d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(240, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping the data set for our model\n",
        "elmo_train_new = elmo_train_new.reshape(elmo_train_new.shape[0], 1, elmo_train_new.shape[1])"
      ],
      "metadata": {
        "id": "qh5Hfb6bqHwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is converting the categorical labels in the train and test dataframes into numerical labels using the pd.factorize() function from the Pandas library.\n",
        "The factorize() function maps each unique value in a categorical column to a unique numerical label. The resulting labels are integers ranging from 0 to the number of unique categories minus 1.\n",
        "The factorize() function is applied to the category column of both the train and test dataframes using the [0] index to select only the factorized labels, and then assigns the result back to the category column of each dataframe."
      ],
      "metadata": {
        "id": "EOYmW-iTZcMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['category'] = pd.factorize(train['category'])[0]\n",
        "test['category'] = pd.factorize(test['category'])[0]"
      ],
      "metadata": {
        "id": "IYDkg_XmyuOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the additional libraries\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "from tensorflow.keras.layers import Input, Lambda, Bidirectional, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "\n",
        "# Creating a sequential model\n",
        "model_e = Sequential()\n",
        "\n",
        "# Adding a Bidirectional LSTM layer with 128 units and return sequences\n",
        "model_e.add(Bidirectional(LSTM(units=128, return_sequences=True), input_shape=(None, 1024)))\n",
        "\n",
        "# Adding a dropout layer with rate 0.5\n",
        "model_e.add(Dropout(0.5))\n",
        "\n",
        "# Adding another Bidirectional LSTM layer with 64 units\n",
        "model_e.add(Bidirectional(LSTM(units=64)))\n",
        "\n",
        "# Adding another dropout layer with rate 0.5\n",
        "model_e.add(Dropout(0.5))\n",
        "\n",
        "# Adding a flatten layer\n",
        "model_e.add(Flatten())\n",
        "\n",
        "# Adding a dense layer with 1 unit and sigmoid activation\n",
        "model_e.add(Dense(units=3, activation='softmax'))\n",
        "\n",
        "# Compiling the model with adam optimizer and categorical crossentropy loss\n",
        "model_e.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fiting the model with training data and validation split of 0.2, for 10 epochs and batch size 32\n",
        "model_e.fit(elmo_train_new, train['category'], batch_size=32, epochs=10, validation_split=0.2)"
      ],
      "metadata": {
        "id": "fhO6mTQBwNMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "006b785c-a6e2-4d87-8fb8-18f4cc4d4c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 192 samples, validate on 48 samples\n",
            "Epoch 1/10\n",
            " 32/192 [====>.........................] - ETA: 5s - loss: 1.0997 - accuracy: 0.3438"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r192/192 [==============================] - 2s 12ms/sample - loss: 1.0546 - accuracy: 0.6615 - val_loss: 0.9782 - val_accuracy: 0.8125\n",
            "Epoch 2/10\n",
            "192/192 [==============================] - 0s 264us/sample - loss: 0.8919 - accuracy: 0.8385 - val_loss: 0.7587 - val_accuracy: 0.8542\n",
            "Epoch 3/10\n",
            "192/192 [==============================] - 0s 254us/sample - loss: 0.6564 - accuracy: 0.8698 - val_loss: 0.4636 - val_accuracy: 0.8542\n",
            "Epoch 4/10\n",
            "192/192 [==============================] - 0s 257us/sample - loss: 0.3954 - accuracy: 0.8958 - val_loss: 0.2200 - val_accuracy: 0.9583\n",
            "Epoch 5/10\n",
            "192/192 [==============================] - 0s 234us/sample - loss: 0.2236 - accuracy: 0.9271 - val_loss: 0.0851 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "192/192 [==============================] - 0s 239us/sample - loss: 0.1314 - accuracy: 0.9688 - val_loss: 0.0324 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "192/192 [==============================] - 0s 225us/sample - loss: 0.0728 - accuracy: 0.9844 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "192/192 [==============================] - 0s 238us/sample - loss: 0.0482 - accuracy: 0.9948 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "192/192 [==============================] - 0s 238us/sample - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "192/192 [==============================] - 0s 226us/sample - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1db8e83fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "elmo_test_new.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qh_6QsXD2t0A",
        "outputId": "b698c560-d37f-434d-83d2-619726afc196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping the test set to use in the model\n",
        "elmo_test_new = elmo_test_new.reshape(elmo_test_new.shape[0], 1, 1024)"
      ],
      "metadata": {
        "id": "8KQyIrNd2sTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Predicting the labels of the test set using the trained model\n",
        "y_pred = model_e.predict(elmo_test_new)\n"
      ],
      "metadata": {
        "id": "x4mNNPZ-2hkn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6be0511-7865-4aea-98ec-0105ad4df505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I51-gHUv20hH",
        "outputId": "d8a4abe6-1aa4-4adf-a6eb-29d6a71c966c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.99977648e-01, 1.35616483e-05, 8.69925952e-06],\n",
              "       [4.63460929e-05, 9.99905884e-01, 4.76879832e-05],\n",
              "       [4.98003699e-03, 7.10305991e-03, 9.87916827e-01],\n",
              "       [2.05208082e-02, 3.61599756e-04, 9.79117632e-01],\n",
              "       [1.29925672e-06, 9.99996483e-01, 2.20449806e-06],\n",
              "       [1.22073243e-05, 1.61888656e-05, 9.99971569e-01],\n",
              "       [3.13054370e-05, 5.18813249e-05, 9.99916732e-01],\n",
              "       [1.58790976e-03, 9.96765673e-01, 1.64628983e-03],\n",
              "       [2.18267625e-04, 9.99448895e-01, 3.32930125e-04],\n",
              "       [9.99825716e-01, 3.65942033e-05, 1.37784882e-04],\n",
              "       [9.99692321e-01, 1.26512576e-04, 1.81090640e-04],\n",
              "       [2.37049512e-03, 9.94325399e-01, 3.30408057e-03],\n",
              "       [7.56431371e-02, 1.96844945e-03, 9.22388375e-01],\n",
              "       [8.34477603e-01, 1.64829209e-01, 6.93136535e-04],\n",
              "       [1.32530213e-05, 9.99982893e-01, 3.86444844e-06],\n",
              "       [5.97774051e-05, 9.99837160e-01, 1.03059981e-04],\n",
              "       [3.85551721e-05, 1.44127462e-05, 9.99947011e-01],\n",
              "       [4.33044741e-04, 9.99027193e-01, 5.39732457e-04],\n",
              "       [5.84220143e-05, 9.58027376e-05, 9.99845743e-01],\n",
              "       [8.05417970e-02, 1.42920332e-03, 9.18028891e-01],\n",
              "       [3.30551075e-06, 9.99987781e-01, 8.87578517e-06],\n",
              "       [3.28550095e-06, 5.87435170e-06, 9.99990761e-01],\n",
              "       [9.99983370e-01, 9.84012968e-06, 6.70690497e-06],\n",
              "       [1.47543993e-04, 2.10093131e-05, 9.99831438e-01],\n",
              "       [4.08052847e-06, 9.99987185e-01, 8.67104882e-06],\n",
              "       [2.46507011e-06, 5.44853810e-06, 9.99992073e-01],\n",
              "       [7.86964119e-06, 9.99987185e-01, 4.83914846e-06],\n",
              "       [5.78389347e-07, 9.99998391e-01, 9.66782295e-07],\n",
              "       [9.99963582e-01, 2.04443695e-05, 1.58044986e-05],\n",
              "       [6.54452697e-06, 9.99989092e-01, 4.24248765e-06],\n",
              "       [2.14695861e-03, 9.97062624e-01, 7.90350081e-04],\n",
              "       [1.47500294e-04, 9.99695420e-01, 1.57064016e-04],\n",
              "       [1.75329642e-05, 9.51018683e-06, 9.99972880e-01],\n",
              "       [4.29922584e-05, 1.65402071e-05, 9.99940455e-01],\n",
              "       [3.74337942e-05, 9.99890625e-01, 7.19229138e-05],\n",
              "       [1.09478879e-06, 9.99997795e-01, 1.06093353e-06],\n",
              "       [2.54731949e-05, 2.37905362e-04, 9.99736667e-01],\n",
              "       [1.45145459e-04, 2.78074614e-04, 9.99576747e-01],\n",
              "       [1.44000421e-06, 9.99995410e-01, 3.14195154e-06],\n",
              "       [9.99967396e-01, 1.70574585e-05, 1.54867830e-05],\n",
              "       [4.90397453e-01, 2.22729430e-01, 2.86873043e-01],\n",
              "       [1.23201711e-02, 9.67537045e-01, 2.01427378e-02],\n",
              "       [5.59863746e-01, 2.55083770e-01, 1.85052454e-01],\n",
              "       [3.74828763e-02, 8.23613554e-02, 8.80155742e-01],\n",
              "       [4.47968721e-01, 2.15442508e-01, 3.36588740e-01],\n",
              "       [7.10375383e-02, 7.78990269e-01, 1.49972185e-01],\n",
              "       [4.47474440e-06, 2.09253153e-06, 9.99993384e-01],\n",
              "       [3.34686749e-02, 8.79497409e-01, 8.70337933e-02],\n",
              "       [4.38182019e-02, 9.58636403e-02, 8.60318124e-01],\n",
              "       [8.37864637e-01, 4.32190783e-02, 1.18916251e-01],\n",
              "       [7.43428152e-03, 3.19044888e-02, 9.60661173e-01],\n",
              "       [5.22144251e-02, 8.22866201e-01, 1.24919385e-01],\n",
              "       [7.09957257e-02, 7.61897802e-01, 1.67106301e-01],\n",
              "       [6.11480959e-02, 6.93092868e-02, 8.69542599e-01],\n",
              "       [6.18425980e-02, 7.84029007e-01, 1.54128432e-01],\n",
              "       [1.21150836e-02, 9.57178593e-01, 3.07063349e-02],\n",
              "       [1.01164011e-02, 3.48665603e-02, 9.55017030e-01],\n",
              "       [3.48536931e-02, 9.03645575e-01, 6.15007617e-02],\n",
              "       [1.45985223e-02, 4.05415520e-02, 9.44859922e-01],\n",
              "       [1.26533881e-01, 1.48846984e-01, 7.24619091e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define a list of category labels in the order that they appear in the y_pred array\n",
        "test_labels = unique_categories\n",
        "\n",
        "# Get the index of the maximum value in each row of the y_pred array\n",
        "max_indices = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Use the index to look up the corresponding category label in the list\n",
        "predicted_labels = [test_labels[i] for i in max_indices]\n",
        "\n",
        "# Print the predicted labels\n",
        "for i, label in enumerate(predicted_labels):\n",
        "    print(\"Sample {}: {}\".format(i+1, label))\n"
      ],
      "metadata": {
        "id": "IDVOTyDT48v_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7af5eee-476c-4e29-dab3-ec37212fe613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1: tech\n",
            "Sample 2: sport\n",
            "Sample 3: politics\n",
            "Sample 4: politics\n",
            "Sample 5: sport\n",
            "Sample 6: politics\n",
            "Sample 7: politics\n",
            "Sample 8: sport\n",
            "Sample 9: sport\n",
            "Sample 10: tech\n",
            "Sample 11: tech\n",
            "Sample 12: sport\n",
            "Sample 13: politics\n",
            "Sample 14: tech\n",
            "Sample 15: sport\n",
            "Sample 16: sport\n",
            "Sample 17: politics\n",
            "Sample 18: sport\n",
            "Sample 19: politics\n",
            "Sample 20: politics\n",
            "Sample 21: sport\n",
            "Sample 22: politics\n",
            "Sample 23: tech\n",
            "Sample 24: politics\n",
            "Sample 25: sport\n",
            "Sample 26: politics\n",
            "Sample 27: sport\n",
            "Sample 28: sport\n",
            "Sample 29: tech\n",
            "Sample 30: sport\n",
            "Sample 31: sport\n",
            "Sample 32: sport\n",
            "Sample 33: politics\n",
            "Sample 34: politics\n",
            "Sample 35: sport\n",
            "Sample 36: sport\n",
            "Sample 37: politics\n",
            "Sample 38: politics\n",
            "Sample 39: sport\n",
            "Sample 40: tech\n",
            "Sample 41: tech\n",
            "Sample 42: sport\n",
            "Sample 43: tech\n",
            "Sample 44: politics\n",
            "Sample 45: tech\n",
            "Sample 46: sport\n",
            "Sample 47: politics\n",
            "Sample 48: sport\n",
            "Sample 49: politics\n",
            "Sample 50: tech\n",
            "Sample 51: politics\n",
            "Sample 52: sport\n",
            "Sample 53: sport\n",
            "Sample 54: politics\n",
            "Sample 55: sport\n",
            "Sample 56: sport\n",
            "Sample 57: politics\n",
            "Sample 58: sport\n",
            "Sample 59: politics\n",
            "Sample 60: politics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the dataset into testing and training data sets\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "W1aXAboyT1Xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test['predicted_labels'] = predicted_labels\n",
        "test.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "q2BYmEqG5-Q5",
        "outputId": "463c0d07-5cec-4fc1-8242-7838adc28356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     category                                               text  \\\n",
              "351      tech  new consoles promise big problems making games...   \n",
              "465     sport  philippoussis doubt over open bid mark philipp...   \n",
              "256  politics  lib dems  new election pr chief the lib dems h...   \n",
              "16   politics  howard backs stem cell research michael howard...   \n",
              "405     sport  o gara revels in ireland victory ireland fly-h...   \n",
              "\n",
              "                                        tokenized_text predicted_labels  \n",
              "351  [new, console, promise, big, problem, making, ...             tech  \n",
              "465  [philippoussis, doubt, open, bid, mark, philip...            sport  \n",
              "256  [lib, dems, new, election, pr, chief, lib, dem...         politics  \n",
              "16   [howard, back, stem, cell, research, michael, ...         politics  \n",
              "405  [gara, revel, ireland, victory, ireland, flyha...            sport  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77c4ba1c-383f-4ed8-9209-a0fe523a457e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "      <th>tokenized_text</th>\n",
              "      <th>predicted_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>351</th>\n",
              "      <td>tech</td>\n",
              "      <td>new consoles promise big problems making games...</td>\n",
              "      <td>[new, console, promise, big, problem, making, ...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>465</th>\n",
              "      <td>sport</td>\n",
              "      <td>philippoussis doubt over open bid mark philipp...</td>\n",
              "      <td>[philippoussis, doubt, open, bid, mark, philip...</td>\n",
              "      <td>sport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>politics</td>\n",
              "      <td>lib dems  new election pr chief the lib dems h...</td>\n",
              "      <td>[lib, dems, new, election, pr, chief, lib, dem...</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>politics</td>\n",
              "      <td>howard backs stem cell research michael howard...</td>\n",
              "      <td>[howard, back, stem, cell, research, michael, ...</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405</th>\n",
              "      <td>sport</td>\n",
              "      <td>o gara revels in ireland victory ireland fly-h...</td>\n",
              "      <td>[gara, revel, ireland, victory, ireland, flyha...</td>\n",
              "      <td>sport</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77c4ba1c-383f-4ed8-9209-a0fe523a457e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-77c4ba1c-383f-4ed8-9209-a0fe523a457e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-77c4ba1c-383f-4ed8-9209-a0fe523a457e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assigning 'text_positive' column from df to y_true\n",
        "y_true = test['category']\n",
        "\n",
        "# Assigning 'R_pos_count' column from merged to y_pred\n",
        "y_pred = test['predicted_labels']\n",
        "\n",
        "# Calculating confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n"
      ],
      "metadata": {
        "id": "uSKF1a9A6fAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting confusion matrix using matshow function from matplotlib\n",
        "plt.matshow(cm, cmap=plt.cm.Blues)\n",
        "\n",
        "# Adding colorbar to the plot\n",
        "plt.colorbar()\n",
        "\n",
        "\n",
        "# Adding labels to x-axis and y-axis of the plot\n",
        "plt.xlabel(\"True labels\")\n",
        "plt.ylabel(\"Predicted labels \")\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "XZ50EZ136s1z",
        "outputId": "4b95d646-6fc2-47e5-b128-386d2a1fbc22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 480x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtaining a score of how much do two data sets match \n",
        "total_obs = np.sum(cm)\n",
        "correct_classifications = np.diagonal(cm)\n",
        "match_rate = np.sum(correct_classifications) / total_obs\n",
        "print(match_rate)"
      ],
      "metadata": {
        "id": "58is5-g06wdO",
        "outputId": "73c2b62c-4f07-49bc-a2c4-f366861ff36e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9833333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing BiLSTM + Elmo on the New Dataset"
      ],
      "metadata": {
        "id": "sLe2CCtW94Xn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For prediction purposes we use News Category Dataset from Kaggle, which is a collection of news articles published over a period of three years from 2012 to 2015. The dataset includes over 200,000 articles from over 200 different news sources, and is often used for text classification and natural language processing tasks. The dataset has comparable labels, which makes it easy for us to check the accuracy of predictions\n",
        "\n"
      ],
      "metadata": {
        "id": "2STtUNWuaJpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n"
      ],
      "metadata": {
        "id": "wniSfYmH-UPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aafa9b3-923a-483b-f327-425d87682886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "ddk3aK1--ALd",
        "outputId": "15c32958-6f2f-4f42-9283-292c51f776cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4689dbc2-9553-4788-90ea-09f53a319a76\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4689dbc2-9553-4788-90ea-09f53a319a76\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"adilmayo\",\"key\":\"3c772556c90a929fa5c9da2d1afaabcb\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "6PDuB-0Q-aRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d rmisra/news-category-dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIwPbZDf-crt",
        "outputId": "a758dfd0-a696-4f68-8351-8c7f85333e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading news-category-dataset.zip to /content\n",
            " 83% 22.0M/26.5M [00:00<00:00, 113MB/s] \n",
            "100% 26.5M/26.5M [00:00<00:00, 115MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d rmisra/news-category-dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4k4JYC1-Ic2",
        "outputId": "38b16448-0e1b-47d4-99e4-0684c20dabe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "news-category-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip news-category-dataset.zip\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFn3TC1nBsnu",
        "outputId": "ad6a72f2-e6c4-4054-8e56-bc79cf1fde8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  news-category-dataset.zip\n",
            "  inflating: News_Category_Dataset_v3.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_f = pd.read_json('News_Category_Dataset_v3.json', lines=True)"
      ],
      "metadata": {
        "id": "p0dt9buABs9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this code is selecting only the rows from the original dataframe that belong to the specified categories and creating a new dataframe with these rows\n",
        "categories = ['POLITICS', 'ENTERTAINMENT', 'SPORTS', 'BUSINESS', 'TECH']\n",
        "filtered_df = df_f[df_f['category'].isin(categories)]"
      ],
      "metadata": {
        "id": "HZiFjMVADpPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = filtered_df.drop(columns=['link', 'headline', 'authors', 'date']) #dropping uneccassary columns\n"
      ],
      "metadata": {
        "id": "l2C7IdEIE3aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df['category'] = filtered_df['category'].apply(lambda x: x.lower()) #lowercasing the data"
      ],
      "metadata": {
        "id": "_fHRf5YxFR-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "llUiTMK2Gmav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = filtered_df.drop(columns=['index'])"
      ],
      "metadata": {
        "id": "MICHpZJ5HBHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "yfGNckeCEvp5",
        "outputId": "3a5d56e8-ca59-47eb-e735-40d7e44c72e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        category                                  short_description\n",
              "0           tech  One man's claims that he scammed people on the...\n",
              "1         sports  Maury Wills, who helped the Los Angeles Dodger...\n",
              "2  entertainment  For the past 18 months, Hollywood has effectiv...\n",
              "3       politics  President issues vow as tensions with China rise.\n",
              "4       politics  An annual celebration took on a different feel...\n",
              "5         sports  Las Vegas never had a professional sports cham...\n",
              "6  entertainment  The \"Avatar\" director said aspects of his 2009...\n",
              "7       politics  U.S. President Joe Biden, in London for the fu...\n",
              "8  entertainment  The director of the original 1982 film joins a...\n",
              "9       politics  Republican outrage over the shoddy U.S. withdr..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab6bdd16-2e64-4550-a240-1794cb7c0cf2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>short_description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>One man's claims that he scammed people on the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sports</td>\n",
              "      <td>Maury Wills, who helped the Los Angeles Dodger...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>For the past 18 months, Hollywood has effectiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>politics</td>\n",
              "      <td>President issues vow as tensions with China rise.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>politics</td>\n",
              "      <td>An annual celebration took on a different feel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sports</td>\n",
              "      <td>Las Vegas never had a professional sports cham...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>The \"Avatar\" director said aspects of his 2009...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>politics</td>\n",
              "      <td>U.S. President Joe Biden, in London for the fu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>The director of the original 1982 film joins a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>politics</td>\n",
              "      <td>Republican outrage over the shoddy U.S. withdr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab6bdd16-2e64-4550-a240-1794cb7c0cf2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab6bdd16-2e64-4550-a240-1794cb7c0cf2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab6bdd16-2e64-4550-a240-1794cb7c0cf2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(filtered_df[filtered_df['category'] == 'SPORT'])"
      ],
      "metadata": {
        "id": "yJPQrlA_e3mN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We are choosing 400 articles per tag\n",
        "\n",
        "df_p = filtered_df[filtered_df['category'] == 'politics'][:400].copy()\n",
        "df_t = filtered_df[filtered_df['category'] == 'tech'][:400].copy()\n",
        "df_s = filtered_df[filtered_df['category'] == 'sports'][:400].copy()"
      ],
      "metadata": {
        "id": "ARRoCMipI8ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_p =  df_p[:400].copy()\n",
        "df_t =  df_t[:400].copy()\n",
        "df_s =  df_s[:400].copy()"
      ],
      "metadata": {
        "id": "EFHJdPk03N6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNuPn-L1encO",
        "outputId": "3043f827-5ea0-4398-eacf-d8f65cadc8cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final = pd.concat([df_p, df_t, df_s])\n"
      ],
      "metadata": {
        "id": "5NLWTXDZJno4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "U1zDxQFL1NfK",
        "outputId": "01bba6e2-4293-46bb-bd23-602ecc90b6bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    category                                  short_description\n",
              "3   politics  President issues vow as tensions with China rise.\n",
              "4   politics  An annual celebration took on a different feel...\n",
              "7   politics  U.S. President Joe Biden, in London for the fu...\n",
              "9   politics  Republican outrage over the shoddy U.S. withdr...\n",
              "11  politics  The former White House chief of staff has turn..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-afc869d5-0a57-4dde-b545-996d8de5cf72\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>short_description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>politics</td>\n",
              "      <td>President issues vow as tensions with China rise.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>politics</td>\n",
              "      <td>An annual celebration took on a different feel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>politics</td>\n",
              "      <td>U.S. President Joe Biden, in London for the fu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>politics</td>\n",
              "      <td>Republican outrage over the shoddy U.S. withdr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>politics</td>\n",
              "      <td>The former White House chief of staff has turn...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afc869d5-0a57-4dde-b545-996d8de5cf72')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-afc869d5-0a57-4dde-b545-996d8de5cf72 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-afc869d5-0a57-4dde-b545-996d8de5cf72');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6jA-472F2R9",
        "outputId": "8e844b88-ec0f-49cb-ed1b-77472adf55eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1200"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def prep(df, column):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    df[column] = df[column].apply(lambda x: re.sub(r'[^\\w\\s]', '', x)) # remove punctuation\n",
        "    df[column] = df[column].apply(lambda x: x.lower()) # convert text to lowercase\n",
        "    df[column] = df[column].apply(lambda x: [word for word in nltk.word_tokenize(x) if word not in stop_words]) # tokenize and remove stopwords\n",
        "    df[column] = df[column].apply(lambda x: [lemmatizer.lemmatize(word) for word in x]) # lemmatize each word\n",
        "    df[column] = df[column].apply(lambda x: ' '.join(x)) # join the list of words back into a single string\n",
        "    return df\n",
        "\n",
        "\n",
        "prep(final, \"short_description\")"
      ],
      "metadata": {
        "id": "muWXy2f0vZvm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "b86b7d2b-83b7-4c5e-c938-969d5359db40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      category                                  short_description\n",
              "3     politics             president issue vow tension china rise\n",
              "4     politics  annual celebration took different feel russia ...\n",
              "7     politics  u president joe biden london funeral queen eli...\n",
              "9     politics  republican outrage shoddy u withdrawal afghani...\n",
              "11    politics  former white house chief staff turned record p...\n",
              "...        ...                                                ...\n",
              "7962    sports  became first person win three gold medal olymp...\n",
              "7963    sports               im saying weve never seen place time\n",
              "7965    sports  gracie gold vincent zhou chris knierim jeffrey...\n",
              "7967    sports                    later admitted poor choice word\n",
              "7969    sports  one potential beau said friendzoned olympian w...\n",
              "\n",
              "[1200 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a66bbec4-b58d-49b2-b6db-3877df8323ba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>short_description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>politics</td>\n",
              "      <td>president issue vow tension china rise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>politics</td>\n",
              "      <td>annual celebration took different feel russia ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>politics</td>\n",
              "      <td>u president joe biden london funeral queen eli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>politics</td>\n",
              "      <td>republican outrage shoddy u withdrawal afghani...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>politics</td>\n",
              "      <td>former white house chief staff turned record p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7962</th>\n",
              "      <td>sports</td>\n",
              "      <td>became first person win three gold medal olymp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7963</th>\n",
              "      <td>sports</td>\n",
              "      <td>im saying weve never seen place time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7965</th>\n",
              "      <td>sports</td>\n",
              "      <td>gracie gold vincent zhou chris knierim jeffrey...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7967</th>\n",
              "      <td>sports</td>\n",
              "      <td>later admitted poor choice word</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7969</th>\n",
              "      <td>sports</td>\n",
              "      <td>one potential beau said friendzoned olympian w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a66bbec4-b58d-49b2-b6db-3877df8323ba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a66bbec4-b58d-49b2-b6db-3877df8323ba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a66bbec4-b58d-49b2-b6db-3877df8323ba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WLGnqHOJ1bdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#In this code snippet, we are using the sample() method of the DataFrame with the following arguments:\n",
        "#frac=1: This specifies that we want to sample the entire DataFrame, i.e., use all the rows.\n",
        "#random_state=42: This sets the random seed to a fixed value, ensuring that the results are reproducible.\n",
        "import random\n",
        "shuffled_df = final.sample(frac=1, random_state=42)"
      ],
      "metadata": {
        "id": "Um3smpn2GLfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Tfjd4uL97FiA",
        "outputId": "bd3e6aa0-d7ad-4f56-f622-d488639338d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      category                                  short_description\n",
              "7892    sports  youre 28 year old skating best ever life expla...\n",
              "631     sports  really long journey embracing gender pair skat...\n",
              "192   politics  democratic pennsylvania senate nominee found c...\n",
              "5271      tech  facebook engineer fired allegedly selfidentify...\n",
              "112   politics  two veteran new york democrat previously dodge..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40dd0a4a-b3d4-4dfe-9205-6883967df55d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>short_description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7892</th>\n",
              "      <td>sports</td>\n",
              "      <td>youre 28 year old skating best ever life expla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>631</th>\n",
              "      <td>sports</td>\n",
              "      <td>really long journey embracing gender pair skat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>politics</td>\n",
              "      <td>democratic pennsylvania senate nominee found c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5271</th>\n",
              "      <td>tech</td>\n",
              "      <td>facebook engineer fired allegedly selfidentify...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>politics</td>\n",
              "      <td>two veteran new york democrat previously dodge...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40dd0a4a-b3d4-4dfe-9205-6883967df55d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-40dd0a4a-b3d4-4dfe-9205-6883967df55d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-40dd0a4a-b3d4-4dfe-9205-6883967df55d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [shuffled_df[i:i + 100] for i in range(0,shuffled_df.shape[0], 100)]\n"
      ],
      "metadata": {
        "id": "mnjxFpmHKDsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elmo_f = [embedding_elmo(x['short_description']) for x in lst]\n"
      ],
      "metadata": {
        "id": "EzjBuC0kLyba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "elmo_f_new = np.concatenate(elmo_f, axis = 0)"
      ],
      "metadata": {
        "id": "JQ-yfsg4NvWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elmo_f_new = elmo_f_new.reshape(elmo_f_new.shape[0], 1, elmo_f_new.shape[1])"
      ],
      "metadata": {
        "id": "RI22TEdVN0Oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Predicting the labels of the test set using the trained model\n",
        "y_pred = model_e.predict(elmo_f_new)\n"
      ],
      "metadata": {
        "id": "Yb8BPIe-O9SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "UuXkxh6fVZAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2573904d-153a-414b-b43f-9d93509ff90b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.3196921e-01, 8.4932393e-01, 1.8706812e-02],\n",
              "       [4.1286447e-03, 9.9542433e-01, 4.4703129e-04],\n",
              "       [2.1611031e-03, 4.0941224e-02, 9.5689762e-01],\n",
              "       ...,\n",
              "       [2.2677107e-01, 2.4940084e-01, 5.2382815e-01],\n",
              "       [1.3537425e-05, 9.9978256e-01, 2.0393032e-04],\n",
              "       [1.5686586e-01, 4.7893929e-01, 3.6419475e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a list of category labels in the order that they appear in the y_pred array\n",
        "final_labels = unique_categories\n",
        "# Get the index of the maximum value in each row of the y_pred array\n",
        "max_indices = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Use the index to look up the corresponding category label in the list\n",
        "predicted_labels = [final_labels[i] for i in max_indices]\n",
        "\n",
        "# Print the predicted labels\n",
        "for i, label in enumerate(predicted_labels):\n",
        "    print(\"Sample {}: {}\".format(i+1, label))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AKqhD6NikXc",
        "outputId": "d2322fba-c1e4-4767-eeef-8a60eb826a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1: sport\n",
            "Sample 2: sport\n",
            "Sample 3: politics\n",
            "Sample 4: tech\n",
            "Sample 5: politics\n",
            "Sample 6: sport\n",
            "Sample 7: politics\n",
            "Sample 8: sport\n",
            "Sample 9: tech\n",
            "Sample 10: sport\n",
            "Sample 11: politics\n",
            "Sample 12: politics\n",
            "Sample 13: politics\n",
            "Sample 14: sport\n",
            "Sample 15: tech\n",
            "Sample 16: politics\n",
            "Sample 17: politics\n",
            "Sample 18: sport\n",
            "Sample 19: sport\n",
            "Sample 20: tech\n",
            "Sample 21: politics\n",
            "Sample 22: politics\n",
            "Sample 23: tech\n",
            "Sample 24: politics\n",
            "Sample 25: politics\n",
            "Sample 26: tech\n",
            "Sample 27: tech\n",
            "Sample 28: tech\n",
            "Sample 29: politics\n",
            "Sample 30: tech\n",
            "Sample 31: politics\n",
            "Sample 32: sport\n",
            "Sample 33: tech\n",
            "Sample 34: politics\n",
            "Sample 35: politics\n",
            "Sample 36: tech\n",
            "Sample 37: tech\n",
            "Sample 38: tech\n",
            "Sample 39: sport\n",
            "Sample 40: tech\n",
            "Sample 41: sport\n",
            "Sample 42: tech\n",
            "Sample 43: politics\n",
            "Sample 44: politics\n",
            "Sample 45: tech\n",
            "Sample 46: politics\n",
            "Sample 47: politics\n",
            "Sample 48: tech\n",
            "Sample 49: politics\n",
            "Sample 50: politics\n",
            "Sample 51: sport\n",
            "Sample 52: tech\n",
            "Sample 53: tech\n",
            "Sample 54: tech\n",
            "Sample 55: sport\n",
            "Sample 56: tech\n",
            "Sample 57: sport\n",
            "Sample 58: politics\n",
            "Sample 59: sport\n",
            "Sample 60: politics\n",
            "Sample 61: politics\n",
            "Sample 62: sport\n",
            "Sample 63: politics\n",
            "Sample 64: politics\n",
            "Sample 65: politics\n",
            "Sample 66: sport\n",
            "Sample 67: tech\n",
            "Sample 68: tech\n",
            "Sample 69: sport\n",
            "Sample 70: tech\n",
            "Sample 71: tech\n",
            "Sample 72: politics\n",
            "Sample 73: sport\n",
            "Sample 74: politics\n",
            "Sample 75: tech\n",
            "Sample 76: tech\n",
            "Sample 77: tech\n",
            "Sample 78: tech\n",
            "Sample 79: tech\n",
            "Sample 80: sport\n",
            "Sample 81: sport\n",
            "Sample 82: politics\n",
            "Sample 83: sport\n",
            "Sample 84: tech\n",
            "Sample 85: sport\n",
            "Sample 86: sport\n",
            "Sample 87: sport\n",
            "Sample 88: politics\n",
            "Sample 89: sport\n",
            "Sample 90: tech\n",
            "Sample 91: tech\n",
            "Sample 92: politics\n",
            "Sample 93: tech\n",
            "Sample 94: politics\n",
            "Sample 95: tech\n",
            "Sample 96: sport\n",
            "Sample 97: tech\n",
            "Sample 98: sport\n",
            "Sample 99: politics\n",
            "Sample 100: politics\n",
            "Sample 101: tech\n",
            "Sample 102: politics\n",
            "Sample 103: sport\n",
            "Sample 104: politics\n",
            "Sample 105: sport\n",
            "Sample 106: tech\n",
            "Sample 107: sport\n",
            "Sample 108: sport\n",
            "Sample 109: tech\n",
            "Sample 110: sport\n",
            "Sample 111: politics\n",
            "Sample 112: sport\n",
            "Sample 113: politics\n",
            "Sample 114: sport\n",
            "Sample 115: politics\n",
            "Sample 116: sport\n",
            "Sample 117: politics\n",
            "Sample 118: politics\n",
            "Sample 119: politics\n",
            "Sample 120: politics\n",
            "Sample 121: tech\n",
            "Sample 122: tech\n",
            "Sample 123: politics\n",
            "Sample 124: sport\n",
            "Sample 125: politics\n",
            "Sample 126: sport\n",
            "Sample 127: politics\n",
            "Sample 128: politics\n",
            "Sample 129: tech\n",
            "Sample 130: politics\n",
            "Sample 131: politics\n",
            "Sample 132: tech\n",
            "Sample 133: tech\n",
            "Sample 134: tech\n",
            "Sample 135: sport\n",
            "Sample 136: tech\n",
            "Sample 137: tech\n",
            "Sample 138: tech\n",
            "Sample 139: tech\n",
            "Sample 140: sport\n",
            "Sample 141: sport\n",
            "Sample 142: tech\n",
            "Sample 143: politics\n",
            "Sample 144: tech\n",
            "Sample 145: politics\n",
            "Sample 146: tech\n",
            "Sample 147: tech\n",
            "Sample 148: tech\n",
            "Sample 149: tech\n",
            "Sample 150: tech\n",
            "Sample 151: sport\n",
            "Sample 152: politics\n",
            "Sample 153: tech\n",
            "Sample 154: politics\n",
            "Sample 155: sport\n",
            "Sample 156: tech\n",
            "Sample 157: politics\n",
            "Sample 158: politics\n",
            "Sample 159: sport\n",
            "Sample 160: sport\n",
            "Sample 161: politics\n",
            "Sample 162: politics\n",
            "Sample 163: sport\n",
            "Sample 164: tech\n",
            "Sample 165: tech\n",
            "Sample 166: sport\n",
            "Sample 167: politics\n",
            "Sample 168: tech\n",
            "Sample 169: sport\n",
            "Sample 170: politics\n",
            "Sample 171: tech\n",
            "Sample 172: sport\n",
            "Sample 173: politics\n",
            "Sample 174: sport\n",
            "Sample 175: politics\n",
            "Sample 176: tech\n",
            "Sample 177: politics\n",
            "Sample 178: sport\n",
            "Sample 179: tech\n",
            "Sample 180: tech\n",
            "Sample 181: tech\n",
            "Sample 182: sport\n",
            "Sample 183: politics\n",
            "Sample 184: tech\n",
            "Sample 185: politics\n",
            "Sample 186: sport\n",
            "Sample 187: tech\n",
            "Sample 188: tech\n",
            "Sample 189: tech\n",
            "Sample 190: tech\n",
            "Sample 191: sport\n",
            "Sample 192: tech\n",
            "Sample 193: sport\n",
            "Sample 194: sport\n",
            "Sample 195: politics\n",
            "Sample 196: politics\n",
            "Sample 197: sport\n",
            "Sample 198: tech\n",
            "Sample 199: politics\n",
            "Sample 200: tech\n",
            "Sample 201: sport\n",
            "Sample 202: politics\n",
            "Sample 203: politics\n",
            "Sample 204: sport\n",
            "Sample 205: sport\n",
            "Sample 206: politics\n",
            "Sample 207: tech\n",
            "Sample 208: sport\n",
            "Sample 209: tech\n",
            "Sample 210: sport\n",
            "Sample 211: sport\n",
            "Sample 212: politics\n",
            "Sample 213: politics\n",
            "Sample 214: sport\n",
            "Sample 215: tech\n",
            "Sample 216: politics\n",
            "Sample 217: sport\n",
            "Sample 218: politics\n",
            "Sample 219: tech\n",
            "Sample 220: tech\n",
            "Sample 221: sport\n",
            "Sample 222: tech\n",
            "Sample 223: tech\n",
            "Sample 224: sport\n",
            "Sample 225: politics\n",
            "Sample 226: tech\n",
            "Sample 227: tech\n",
            "Sample 228: sport\n",
            "Sample 229: politics\n",
            "Sample 230: tech\n",
            "Sample 231: sport\n",
            "Sample 232: politics\n",
            "Sample 233: sport\n",
            "Sample 234: tech\n",
            "Sample 235: sport\n",
            "Sample 236: politics\n",
            "Sample 237: sport\n",
            "Sample 238: tech\n",
            "Sample 239: sport\n",
            "Sample 240: sport\n",
            "Sample 241: politics\n",
            "Sample 242: tech\n",
            "Sample 243: politics\n",
            "Sample 244: sport\n",
            "Sample 245: tech\n",
            "Sample 246: tech\n",
            "Sample 247: tech\n",
            "Sample 248: politics\n",
            "Sample 249: politics\n",
            "Sample 250: politics\n",
            "Sample 251: sport\n",
            "Sample 252: politics\n",
            "Sample 253: tech\n",
            "Sample 254: politics\n",
            "Sample 255: sport\n",
            "Sample 256: sport\n",
            "Sample 257: politics\n",
            "Sample 258: tech\n",
            "Sample 259: politics\n",
            "Sample 260: tech\n",
            "Sample 261: tech\n",
            "Sample 262: politics\n",
            "Sample 263: sport\n",
            "Sample 264: tech\n",
            "Sample 265: tech\n",
            "Sample 266: tech\n",
            "Sample 267: tech\n",
            "Sample 268: tech\n",
            "Sample 269: politics\n",
            "Sample 270: tech\n",
            "Sample 271: tech\n",
            "Sample 272: tech\n",
            "Sample 273: tech\n",
            "Sample 274: sport\n",
            "Sample 275: politics\n",
            "Sample 276: politics\n",
            "Sample 277: politics\n",
            "Sample 278: politics\n",
            "Sample 279: sport\n",
            "Sample 280: politics\n",
            "Sample 281: tech\n",
            "Sample 282: sport\n",
            "Sample 283: politics\n",
            "Sample 284: sport\n",
            "Sample 285: tech\n",
            "Sample 286: sport\n",
            "Sample 287: tech\n",
            "Sample 288: sport\n",
            "Sample 289: politics\n",
            "Sample 290: sport\n",
            "Sample 291: tech\n",
            "Sample 292: sport\n",
            "Sample 293: tech\n",
            "Sample 294: sport\n",
            "Sample 295: politics\n",
            "Sample 296: tech\n",
            "Sample 297: tech\n",
            "Sample 298: sport\n",
            "Sample 299: sport\n",
            "Sample 300: tech\n",
            "Sample 301: sport\n",
            "Sample 302: sport\n",
            "Sample 303: politics\n",
            "Sample 304: sport\n",
            "Sample 305: tech\n",
            "Sample 306: sport\n",
            "Sample 307: sport\n",
            "Sample 308: politics\n",
            "Sample 309: politics\n",
            "Sample 310: sport\n",
            "Sample 311: politics\n",
            "Sample 312: politics\n",
            "Sample 313: politics\n",
            "Sample 314: sport\n",
            "Sample 315: politics\n",
            "Sample 316: tech\n",
            "Sample 317: tech\n",
            "Sample 318: sport\n",
            "Sample 319: tech\n",
            "Sample 320: sport\n",
            "Sample 321: sport\n",
            "Sample 322: sport\n",
            "Sample 323: tech\n",
            "Sample 324: tech\n",
            "Sample 325: sport\n",
            "Sample 326: tech\n",
            "Sample 327: sport\n",
            "Sample 328: tech\n",
            "Sample 329: politics\n",
            "Sample 330: tech\n",
            "Sample 331: tech\n",
            "Sample 332: politics\n",
            "Sample 333: politics\n",
            "Sample 334: politics\n",
            "Sample 335: sport\n",
            "Sample 336: tech\n",
            "Sample 337: politics\n",
            "Sample 338: politics\n",
            "Sample 339: sport\n",
            "Sample 340: politics\n",
            "Sample 341: politics\n",
            "Sample 342: politics\n",
            "Sample 343: sport\n",
            "Sample 344: tech\n",
            "Sample 345: tech\n",
            "Sample 346: tech\n",
            "Sample 347: tech\n",
            "Sample 348: sport\n",
            "Sample 349: politics\n",
            "Sample 350: tech\n",
            "Sample 351: politics\n",
            "Sample 352: politics\n",
            "Sample 353: politics\n",
            "Sample 354: sport\n",
            "Sample 355: tech\n",
            "Sample 356: politics\n",
            "Sample 357: politics\n",
            "Sample 358: politics\n",
            "Sample 359: politics\n",
            "Sample 360: tech\n",
            "Sample 361: politics\n",
            "Sample 362: tech\n",
            "Sample 363: tech\n",
            "Sample 364: sport\n",
            "Sample 365: tech\n",
            "Sample 366: tech\n",
            "Sample 367: politics\n",
            "Sample 368: sport\n",
            "Sample 369: tech\n",
            "Sample 370: sport\n",
            "Sample 371: tech\n",
            "Sample 372: tech\n",
            "Sample 373: politics\n",
            "Sample 374: politics\n",
            "Sample 375: tech\n",
            "Sample 376: politics\n",
            "Sample 377: sport\n",
            "Sample 378: politics\n",
            "Sample 379: sport\n",
            "Sample 380: politics\n",
            "Sample 381: sport\n",
            "Sample 382: sport\n",
            "Sample 383: tech\n",
            "Sample 384: sport\n",
            "Sample 385: tech\n",
            "Sample 386: sport\n",
            "Sample 387: politics\n",
            "Sample 388: tech\n",
            "Sample 389: politics\n",
            "Sample 390: tech\n",
            "Sample 391: tech\n",
            "Sample 392: tech\n",
            "Sample 393: sport\n",
            "Sample 394: politics\n",
            "Sample 395: tech\n",
            "Sample 396: politics\n",
            "Sample 397: politics\n",
            "Sample 398: tech\n",
            "Sample 399: tech\n",
            "Sample 400: tech\n",
            "Sample 401: tech\n",
            "Sample 402: sport\n",
            "Sample 403: tech\n",
            "Sample 404: sport\n",
            "Sample 405: sport\n",
            "Sample 406: politics\n",
            "Sample 407: politics\n",
            "Sample 408: politics\n",
            "Sample 409: tech\n",
            "Sample 410: tech\n",
            "Sample 411: tech\n",
            "Sample 412: tech\n",
            "Sample 413: tech\n",
            "Sample 414: tech\n",
            "Sample 415: tech\n",
            "Sample 416: politics\n",
            "Sample 417: tech\n",
            "Sample 418: sport\n",
            "Sample 419: tech\n",
            "Sample 420: tech\n",
            "Sample 421: politics\n",
            "Sample 422: politics\n",
            "Sample 423: sport\n",
            "Sample 424: tech\n",
            "Sample 425: tech\n",
            "Sample 426: politics\n",
            "Sample 427: tech\n",
            "Sample 428: sport\n",
            "Sample 429: tech\n",
            "Sample 430: tech\n",
            "Sample 431: politics\n",
            "Sample 432: politics\n",
            "Sample 433: tech\n",
            "Sample 434: politics\n",
            "Sample 435: tech\n",
            "Sample 436: politics\n",
            "Sample 437: politics\n",
            "Sample 438: politics\n",
            "Sample 439: sport\n",
            "Sample 440: politics\n",
            "Sample 441: tech\n",
            "Sample 442: tech\n",
            "Sample 443: sport\n",
            "Sample 444: sport\n",
            "Sample 445: sport\n",
            "Sample 446: tech\n",
            "Sample 447: sport\n",
            "Sample 448: tech\n",
            "Sample 449: politics\n",
            "Sample 450: politics\n",
            "Sample 451: tech\n",
            "Sample 452: tech\n",
            "Sample 453: politics\n",
            "Sample 454: sport\n",
            "Sample 455: sport\n",
            "Sample 456: politics\n",
            "Sample 457: politics\n",
            "Sample 458: sport\n",
            "Sample 459: sport\n",
            "Sample 460: politics\n",
            "Sample 461: tech\n",
            "Sample 462: tech\n",
            "Sample 463: politics\n",
            "Sample 464: tech\n",
            "Sample 465: sport\n",
            "Sample 466: tech\n",
            "Sample 467: tech\n",
            "Sample 468: politics\n",
            "Sample 469: tech\n",
            "Sample 470: sport\n",
            "Sample 471: sport\n",
            "Sample 472: tech\n",
            "Sample 473: sport\n",
            "Sample 474: tech\n",
            "Sample 475: tech\n",
            "Sample 476: tech\n",
            "Sample 477: politics\n",
            "Sample 478: politics\n",
            "Sample 479: tech\n",
            "Sample 480: tech\n",
            "Sample 481: sport\n",
            "Sample 482: tech\n",
            "Sample 483: tech\n",
            "Sample 484: tech\n",
            "Sample 485: tech\n",
            "Sample 486: tech\n",
            "Sample 487: tech\n",
            "Sample 488: tech\n",
            "Sample 489: politics\n",
            "Sample 490: politics\n",
            "Sample 491: sport\n",
            "Sample 492: tech\n",
            "Sample 493: politics\n",
            "Sample 494: tech\n",
            "Sample 495: tech\n",
            "Sample 496: tech\n",
            "Sample 497: sport\n",
            "Sample 498: tech\n",
            "Sample 499: sport\n",
            "Sample 500: tech\n",
            "Sample 501: politics\n",
            "Sample 502: tech\n",
            "Sample 503: tech\n",
            "Sample 504: tech\n",
            "Sample 505: sport\n",
            "Sample 506: tech\n",
            "Sample 507: sport\n",
            "Sample 508: sport\n",
            "Sample 509: sport\n",
            "Sample 510: politics\n",
            "Sample 511: politics\n",
            "Sample 512: tech\n",
            "Sample 513: tech\n",
            "Sample 514: sport\n",
            "Sample 515: sport\n",
            "Sample 516: sport\n",
            "Sample 517: politics\n",
            "Sample 518: tech\n",
            "Sample 519: tech\n",
            "Sample 520: politics\n",
            "Sample 521: politics\n",
            "Sample 522: politics\n",
            "Sample 523: politics\n",
            "Sample 524: politics\n",
            "Sample 525: politics\n",
            "Sample 526: tech\n",
            "Sample 527: politics\n",
            "Sample 528: politics\n",
            "Sample 529: sport\n",
            "Sample 530: politics\n",
            "Sample 531: sport\n",
            "Sample 532: tech\n",
            "Sample 533: tech\n",
            "Sample 534: tech\n",
            "Sample 535: politics\n",
            "Sample 536: sport\n",
            "Sample 537: tech\n",
            "Sample 538: tech\n",
            "Sample 539: sport\n",
            "Sample 540: tech\n",
            "Sample 541: sport\n",
            "Sample 542: tech\n",
            "Sample 543: politics\n",
            "Sample 544: sport\n",
            "Sample 545: sport\n",
            "Sample 546: tech\n",
            "Sample 547: sport\n",
            "Sample 548: sport\n",
            "Sample 549: sport\n",
            "Sample 550: sport\n",
            "Sample 551: politics\n",
            "Sample 552: politics\n",
            "Sample 553: sport\n",
            "Sample 554: sport\n",
            "Sample 555: sport\n",
            "Sample 556: sport\n",
            "Sample 557: sport\n",
            "Sample 558: tech\n",
            "Sample 559: sport\n",
            "Sample 560: tech\n",
            "Sample 561: politics\n",
            "Sample 562: tech\n",
            "Sample 563: politics\n",
            "Sample 564: sport\n",
            "Sample 565: tech\n",
            "Sample 566: tech\n",
            "Sample 567: tech\n",
            "Sample 568: politics\n",
            "Sample 569: sport\n",
            "Sample 570: politics\n",
            "Sample 571: politics\n",
            "Sample 572: politics\n",
            "Sample 573: tech\n",
            "Sample 574: politics\n",
            "Sample 575: sport\n",
            "Sample 576: sport\n",
            "Sample 577: politics\n",
            "Sample 578: tech\n",
            "Sample 579: sport\n",
            "Sample 580: tech\n",
            "Sample 581: sport\n",
            "Sample 582: tech\n",
            "Sample 583: tech\n",
            "Sample 584: politics\n",
            "Sample 585: politics\n",
            "Sample 586: politics\n",
            "Sample 587: tech\n",
            "Sample 588: sport\n",
            "Sample 589: tech\n",
            "Sample 590: tech\n",
            "Sample 591: tech\n",
            "Sample 592: politics\n",
            "Sample 593: sport\n",
            "Sample 594: politics\n",
            "Sample 595: sport\n",
            "Sample 596: tech\n",
            "Sample 597: politics\n",
            "Sample 598: sport\n",
            "Sample 599: tech\n",
            "Sample 600: politics\n",
            "Sample 601: tech\n",
            "Sample 602: politics\n",
            "Sample 603: politics\n",
            "Sample 604: politics\n",
            "Sample 605: politics\n",
            "Sample 606: sport\n",
            "Sample 607: tech\n",
            "Sample 608: sport\n",
            "Sample 609: tech\n",
            "Sample 610: tech\n",
            "Sample 611: sport\n",
            "Sample 612: sport\n",
            "Sample 613: politics\n",
            "Sample 614: sport\n",
            "Sample 615: sport\n",
            "Sample 616: tech\n",
            "Sample 617: tech\n",
            "Sample 618: tech\n",
            "Sample 619: sport\n",
            "Sample 620: politics\n",
            "Sample 621: politics\n",
            "Sample 622: politics\n",
            "Sample 623: tech\n",
            "Sample 624: sport\n",
            "Sample 625: sport\n",
            "Sample 626: sport\n",
            "Sample 627: politics\n",
            "Sample 628: sport\n",
            "Sample 629: sport\n",
            "Sample 630: politics\n",
            "Sample 631: sport\n",
            "Sample 632: sport\n",
            "Sample 633: politics\n",
            "Sample 634: politics\n",
            "Sample 635: politics\n",
            "Sample 636: sport\n",
            "Sample 637: politics\n",
            "Sample 638: politics\n",
            "Sample 639: politics\n",
            "Sample 640: sport\n",
            "Sample 641: tech\n",
            "Sample 642: tech\n",
            "Sample 643: politics\n",
            "Sample 644: sport\n",
            "Sample 645: tech\n",
            "Sample 646: tech\n",
            "Sample 647: politics\n",
            "Sample 648: tech\n",
            "Sample 649: tech\n",
            "Sample 650: tech\n",
            "Sample 651: tech\n",
            "Sample 652: politics\n",
            "Sample 653: sport\n",
            "Sample 654: sport\n",
            "Sample 655: tech\n",
            "Sample 656: tech\n",
            "Sample 657: politics\n",
            "Sample 658: tech\n",
            "Sample 659: sport\n",
            "Sample 660: politics\n",
            "Sample 661: politics\n",
            "Sample 662: tech\n",
            "Sample 663: politics\n",
            "Sample 664: politics\n",
            "Sample 665: sport\n",
            "Sample 666: sport\n",
            "Sample 667: tech\n",
            "Sample 668: sport\n",
            "Sample 669: politics\n",
            "Sample 670: sport\n",
            "Sample 671: politics\n",
            "Sample 672: tech\n",
            "Sample 673: politics\n",
            "Sample 674: sport\n",
            "Sample 675: sport\n",
            "Sample 676: sport\n",
            "Sample 677: politics\n",
            "Sample 678: politics\n",
            "Sample 679: tech\n",
            "Sample 680: tech\n",
            "Sample 681: sport\n",
            "Sample 682: tech\n",
            "Sample 683: tech\n",
            "Sample 684: sport\n",
            "Sample 685: sport\n",
            "Sample 686: sport\n",
            "Sample 687: politics\n",
            "Sample 688: politics\n",
            "Sample 689: politics\n",
            "Sample 690: tech\n",
            "Sample 691: tech\n",
            "Sample 692: tech\n",
            "Sample 693: tech\n",
            "Sample 694: tech\n",
            "Sample 695: tech\n",
            "Sample 696: tech\n",
            "Sample 697: politics\n",
            "Sample 698: tech\n",
            "Sample 699: tech\n",
            "Sample 700: sport\n",
            "Sample 701: sport\n",
            "Sample 702: tech\n",
            "Sample 703: politics\n",
            "Sample 704: sport\n",
            "Sample 705: politics\n",
            "Sample 706: politics\n",
            "Sample 707: tech\n",
            "Sample 708: tech\n",
            "Sample 709: politics\n",
            "Sample 710: politics\n",
            "Sample 711: tech\n",
            "Sample 712: tech\n",
            "Sample 713: politics\n",
            "Sample 714: tech\n",
            "Sample 715: politics\n",
            "Sample 716: tech\n",
            "Sample 717: tech\n",
            "Sample 718: tech\n",
            "Sample 719: tech\n",
            "Sample 720: tech\n",
            "Sample 721: sport\n",
            "Sample 722: sport\n",
            "Sample 723: sport\n",
            "Sample 724: sport\n",
            "Sample 725: politics\n",
            "Sample 726: tech\n",
            "Sample 727: politics\n",
            "Sample 728: sport\n",
            "Sample 729: tech\n",
            "Sample 730: tech\n",
            "Sample 731: tech\n",
            "Sample 732: politics\n",
            "Sample 733: politics\n",
            "Sample 734: politics\n",
            "Sample 735: politics\n",
            "Sample 736: politics\n",
            "Sample 737: tech\n",
            "Sample 738: politics\n",
            "Sample 739: tech\n",
            "Sample 740: sport\n",
            "Sample 741: sport\n",
            "Sample 742: tech\n",
            "Sample 743: sport\n",
            "Sample 744: politics\n",
            "Sample 745: tech\n",
            "Sample 746: sport\n",
            "Sample 747: tech\n",
            "Sample 748: politics\n",
            "Sample 749: tech\n",
            "Sample 750: tech\n",
            "Sample 751: politics\n",
            "Sample 752: sport\n",
            "Sample 753: sport\n",
            "Sample 754: politics\n",
            "Sample 755: politics\n",
            "Sample 756: tech\n",
            "Sample 757: tech\n",
            "Sample 758: tech\n",
            "Sample 759: tech\n",
            "Sample 760: politics\n",
            "Sample 761: tech\n",
            "Sample 762: tech\n",
            "Sample 763: sport\n",
            "Sample 764: tech\n",
            "Sample 765: tech\n",
            "Sample 766: politics\n",
            "Sample 767: tech\n",
            "Sample 768: politics\n",
            "Sample 769: tech\n",
            "Sample 770: politics\n",
            "Sample 771: tech\n",
            "Sample 772: politics\n",
            "Sample 773: tech\n",
            "Sample 774: sport\n",
            "Sample 775: tech\n",
            "Sample 776: tech\n",
            "Sample 777: tech\n",
            "Sample 778: politics\n",
            "Sample 779: sport\n",
            "Sample 780: politics\n",
            "Sample 781: politics\n",
            "Sample 782: sport\n",
            "Sample 783: tech\n",
            "Sample 784: tech\n",
            "Sample 785: sport\n",
            "Sample 786: politics\n",
            "Sample 787: tech\n",
            "Sample 788: tech\n",
            "Sample 789: sport\n",
            "Sample 790: tech\n",
            "Sample 791: politics\n",
            "Sample 792: tech\n",
            "Sample 793: tech\n",
            "Sample 794: tech\n",
            "Sample 795: politics\n",
            "Sample 796: politics\n",
            "Sample 797: sport\n",
            "Sample 798: politics\n",
            "Sample 799: politics\n",
            "Sample 800: tech\n",
            "Sample 801: politics\n",
            "Sample 802: tech\n",
            "Sample 803: politics\n",
            "Sample 804: sport\n",
            "Sample 805: tech\n",
            "Sample 806: tech\n",
            "Sample 807: tech\n",
            "Sample 808: tech\n",
            "Sample 809: tech\n",
            "Sample 810: sport\n",
            "Sample 811: politics\n",
            "Sample 812: tech\n",
            "Sample 813: tech\n",
            "Sample 814: politics\n",
            "Sample 815: tech\n",
            "Sample 816: sport\n",
            "Sample 817: politics\n",
            "Sample 818: politics\n",
            "Sample 819: politics\n",
            "Sample 820: sport\n",
            "Sample 821: tech\n",
            "Sample 822: tech\n",
            "Sample 823: sport\n",
            "Sample 824: tech\n",
            "Sample 825: politics\n",
            "Sample 826: tech\n",
            "Sample 827: politics\n",
            "Sample 828: sport\n",
            "Sample 829: sport\n",
            "Sample 830: politics\n",
            "Sample 831: tech\n",
            "Sample 832: politics\n",
            "Sample 833: tech\n",
            "Sample 834: politics\n",
            "Sample 835: politics\n",
            "Sample 836: politics\n",
            "Sample 837: tech\n",
            "Sample 838: sport\n",
            "Sample 839: sport\n",
            "Sample 840: tech\n",
            "Sample 841: sport\n",
            "Sample 842: politics\n",
            "Sample 843: tech\n",
            "Sample 844: sport\n",
            "Sample 845: tech\n",
            "Sample 846: tech\n",
            "Sample 847: sport\n",
            "Sample 848: sport\n",
            "Sample 849: politics\n",
            "Sample 850: politics\n",
            "Sample 851: politics\n",
            "Sample 852: sport\n",
            "Sample 853: sport\n",
            "Sample 854: sport\n",
            "Sample 855: tech\n",
            "Sample 856: politics\n",
            "Sample 857: tech\n",
            "Sample 858: politics\n",
            "Sample 859: politics\n",
            "Sample 860: tech\n",
            "Sample 861: sport\n",
            "Sample 862: sport\n",
            "Sample 863: tech\n",
            "Sample 864: sport\n",
            "Sample 865: tech\n",
            "Sample 866: sport\n",
            "Sample 867: tech\n",
            "Sample 868: sport\n",
            "Sample 869: politics\n",
            "Sample 870: tech\n",
            "Sample 871: sport\n",
            "Sample 872: politics\n",
            "Sample 873: politics\n",
            "Sample 874: sport\n",
            "Sample 875: sport\n",
            "Sample 876: sport\n",
            "Sample 877: politics\n",
            "Sample 878: politics\n",
            "Sample 879: sport\n",
            "Sample 880: tech\n",
            "Sample 881: politics\n",
            "Sample 882: politics\n",
            "Sample 883: politics\n",
            "Sample 884: tech\n",
            "Sample 885: politics\n",
            "Sample 886: sport\n",
            "Sample 887: sport\n",
            "Sample 888: tech\n",
            "Sample 889: sport\n",
            "Sample 890: tech\n",
            "Sample 891: politics\n",
            "Sample 892: sport\n",
            "Sample 893: politics\n",
            "Sample 894: politics\n",
            "Sample 895: sport\n",
            "Sample 896: politics\n",
            "Sample 897: politics\n",
            "Sample 898: sport\n",
            "Sample 899: politics\n",
            "Sample 900: politics\n",
            "Sample 901: politics\n",
            "Sample 902: tech\n",
            "Sample 903: sport\n",
            "Sample 904: sport\n",
            "Sample 905: sport\n",
            "Sample 906: sport\n",
            "Sample 907: politics\n",
            "Sample 908: tech\n",
            "Sample 909: politics\n",
            "Sample 910: sport\n",
            "Sample 911: tech\n",
            "Sample 912: tech\n",
            "Sample 913: tech\n",
            "Sample 914: tech\n",
            "Sample 915: tech\n",
            "Sample 916: sport\n",
            "Sample 917: tech\n",
            "Sample 918: politics\n",
            "Sample 919: politics\n",
            "Sample 920: tech\n",
            "Sample 921: politics\n",
            "Sample 922: tech\n",
            "Sample 923: politics\n",
            "Sample 924: sport\n",
            "Sample 925: sport\n",
            "Sample 926: tech\n",
            "Sample 927: sport\n",
            "Sample 928: sport\n",
            "Sample 929: tech\n",
            "Sample 930: politics\n",
            "Sample 931: sport\n",
            "Sample 932: sport\n",
            "Sample 933: politics\n",
            "Sample 934: sport\n",
            "Sample 935: sport\n",
            "Sample 936: sport\n",
            "Sample 937: tech\n",
            "Sample 938: sport\n",
            "Sample 939: politics\n",
            "Sample 940: tech\n",
            "Sample 941: sport\n",
            "Sample 942: sport\n",
            "Sample 943: sport\n",
            "Sample 944: politics\n",
            "Sample 945: tech\n",
            "Sample 946: sport\n",
            "Sample 947: politics\n",
            "Sample 948: sport\n",
            "Sample 949: sport\n",
            "Sample 950: tech\n",
            "Sample 951: sport\n",
            "Sample 952: tech\n",
            "Sample 953: sport\n",
            "Sample 954: politics\n",
            "Sample 955: sport\n",
            "Sample 956: sport\n",
            "Sample 957: tech\n",
            "Sample 958: tech\n",
            "Sample 959: tech\n",
            "Sample 960: politics\n",
            "Sample 961: sport\n",
            "Sample 962: sport\n",
            "Sample 963: politics\n",
            "Sample 964: tech\n",
            "Sample 965: tech\n",
            "Sample 966: tech\n",
            "Sample 967: tech\n",
            "Sample 968: sport\n",
            "Sample 969: sport\n",
            "Sample 970: tech\n",
            "Sample 971: politics\n",
            "Sample 972: politics\n",
            "Sample 973: politics\n",
            "Sample 974: tech\n",
            "Sample 975: tech\n",
            "Sample 976: politics\n",
            "Sample 977: sport\n",
            "Sample 978: sport\n",
            "Sample 979: politics\n",
            "Sample 980: tech\n",
            "Sample 981: politics\n",
            "Sample 982: politics\n",
            "Sample 983: politics\n",
            "Sample 984: tech\n",
            "Sample 985: tech\n",
            "Sample 986: politics\n",
            "Sample 987: politics\n",
            "Sample 988: sport\n",
            "Sample 989: sport\n",
            "Sample 990: sport\n",
            "Sample 991: tech\n",
            "Sample 992: politics\n",
            "Sample 993: sport\n",
            "Sample 994: sport\n",
            "Sample 995: sport\n",
            "Sample 996: sport\n",
            "Sample 997: tech\n",
            "Sample 998: politics\n",
            "Sample 999: sport\n",
            "Sample 1000: tech\n",
            "Sample 1001: politics\n",
            "Sample 1002: sport\n",
            "Sample 1003: tech\n",
            "Sample 1004: sport\n",
            "Sample 1005: sport\n",
            "Sample 1006: tech\n",
            "Sample 1007: tech\n",
            "Sample 1008: sport\n",
            "Sample 1009: tech\n",
            "Sample 1010: tech\n",
            "Sample 1011: politics\n",
            "Sample 1012: tech\n",
            "Sample 1013: sport\n",
            "Sample 1014: tech\n",
            "Sample 1015: sport\n",
            "Sample 1016: tech\n",
            "Sample 1017: sport\n",
            "Sample 1018: politics\n",
            "Sample 1019: politics\n",
            "Sample 1020: sport\n",
            "Sample 1021: sport\n",
            "Sample 1022: politics\n",
            "Sample 1023: tech\n",
            "Sample 1024: tech\n",
            "Sample 1025: sport\n",
            "Sample 1026: tech\n",
            "Sample 1027: tech\n",
            "Sample 1028: tech\n",
            "Sample 1029: politics\n",
            "Sample 1030: tech\n",
            "Sample 1031: politics\n",
            "Sample 1032: tech\n",
            "Sample 1033: sport\n",
            "Sample 1034: politics\n",
            "Sample 1035: tech\n",
            "Sample 1036: politics\n",
            "Sample 1037: politics\n",
            "Sample 1038: tech\n",
            "Sample 1039: tech\n",
            "Sample 1040: tech\n",
            "Sample 1041: politics\n",
            "Sample 1042: politics\n",
            "Sample 1043: politics\n",
            "Sample 1044: sport\n",
            "Sample 1045: politics\n",
            "Sample 1046: sport\n",
            "Sample 1047: politics\n",
            "Sample 1048: tech\n",
            "Sample 1049: tech\n",
            "Sample 1050: politics\n",
            "Sample 1051: politics\n",
            "Sample 1052: sport\n",
            "Sample 1053: politics\n",
            "Sample 1054: tech\n",
            "Sample 1055: politics\n",
            "Sample 1056: politics\n",
            "Sample 1057: politics\n",
            "Sample 1058: politics\n",
            "Sample 1059: sport\n",
            "Sample 1060: tech\n",
            "Sample 1061: politics\n",
            "Sample 1062: tech\n",
            "Sample 1063: tech\n",
            "Sample 1064: sport\n",
            "Sample 1065: politics\n",
            "Sample 1066: tech\n",
            "Sample 1067: tech\n",
            "Sample 1068: tech\n",
            "Sample 1069: tech\n",
            "Sample 1070: tech\n",
            "Sample 1071: tech\n",
            "Sample 1072: tech\n",
            "Sample 1073: tech\n",
            "Sample 1074: tech\n",
            "Sample 1075: sport\n",
            "Sample 1076: politics\n",
            "Sample 1077: tech\n",
            "Sample 1078: sport\n",
            "Sample 1079: tech\n",
            "Sample 1080: politics\n",
            "Sample 1081: sport\n",
            "Sample 1082: politics\n",
            "Sample 1083: tech\n",
            "Sample 1084: tech\n",
            "Sample 1085: tech\n",
            "Sample 1086: tech\n",
            "Sample 1087: sport\n",
            "Sample 1088: politics\n",
            "Sample 1089: tech\n",
            "Sample 1090: sport\n",
            "Sample 1091: politics\n",
            "Sample 1092: tech\n",
            "Sample 1093: politics\n",
            "Sample 1094: tech\n",
            "Sample 1095: sport\n",
            "Sample 1096: politics\n",
            "Sample 1097: politics\n",
            "Sample 1098: sport\n",
            "Sample 1099: politics\n",
            "Sample 1100: tech\n",
            "Sample 1101: politics\n",
            "Sample 1102: sport\n",
            "Sample 1103: sport\n",
            "Sample 1104: tech\n",
            "Sample 1105: politics\n",
            "Sample 1106: tech\n",
            "Sample 1107: sport\n",
            "Sample 1108: tech\n",
            "Sample 1109: sport\n",
            "Sample 1110: tech\n",
            "Sample 1111: politics\n",
            "Sample 1112: politics\n",
            "Sample 1113: tech\n",
            "Sample 1114: politics\n",
            "Sample 1115: tech\n",
            "Sample 1116: sport\n",
            "Sample 1117: politics\n",
            "Sample 1118: sport\n",
            "Sample 1119: politics\n",
            "Sample 1120: tech\n",
            "Sample 1121: tech\n",
            "Sample 1122: tech\n",
            "Sample 1123: sport\n",
            "Sample 1124: politics\n",
            "Sample 1125: tech\n",
            "Sample 1126: tech\n",
            "Sample 1127: tech\n",
            "Sample 1128: sport\n",
            "Sample 1129: sport\n",
            "Sample 1130: politics\n",
            "Sample 1131: sport\n",
            "Sample 1132: politics\n",
            "Sample 1133: sport\n",
            "Sample 1134: tech\n",
            "Sample 1135: sport\n",
            "Sample 1136: politics\n",
            "Sample 1137: sport\n",
            "Sample 1138: politics\n",
            "Sample 1139: tech\n",
            "Sample 1140: tech\n",
            "Sample 1141: tech\n",
            "Sample 1142: tech\n",
            "Sample 1143: sport\n",
            "Sample 1144: tech\n",
            "Sample 1145: sport\n",
            "Sample 1146: sport\n",
            "Sample 1147: politics\n",
            "Sample 1148: tech\n",
            "Sample 1149: tech\n",
            "Sample 1150: tech\n",
            "Sample 1151: tech\n",
            "Sample 1152: tech\n",
            "Sample 1153: politics\n",
            "Sample 1154: sport\n",
            "Sample 1155: tech\n",
            "Sample 1156: tech\n",
            "Sample 1157: tech\n",
            "Sample 1158: politics\n",
            "Sample 1159: politics\n",
            "Sample 1160: tech\n",
            "Sample 1161: tech\n",
            "Sample 1162: politics\n",
            "Sample 1163: sport\n",
            "Sample 1164: tech\n",
            "Sample 1165: politics\n",
            "Sample 1166: sport\n",
            "Sample 1167: tech\n",
            "Sample 1168: tech\n",
            "Sample 1169: tech\n",
            "Sample 1170: sport\n",
            "Sample 1171: sport\n",
            "Sample 1172: sport\n",
            "Sample 1173: sport\n",
            "Sample 1174: tech\n",
            "Sample 1175: tech\n",
            "Sample 1176: sport\n",
            "Sample 1177: tech\n",
            "Sample 1178: sport\n",
            "Sample 1179: tech\n",
            "Sample 1180: politics\n",
            "Sample 1181: politics\n",
            "Sample 1182: tech\n",
            "Sample 1183: politics\n",
            "Sample 1184: sport\n",
            "Sample 1185: politics\n",
            "Sample 1186: tech\n",
            "Sample 1187: politics\n",
            "Sample 1188: sport\n",
            "Sample 1189: tech\n",
            "Sample 1190: sport\n",
            "Sample 1191: sport\n",
            "Sample 1192: politics\n",
            "Sample 1193: politics\n",
            "Sample 1194: politics\n",
            "Sample 1195: politics\n",
            "Sample 1196: sport\n",
            "Sample 1197: sport\n",
            "Sample 1198: politics\n",
            "Sample 1199: sport\n",
            "Sample 1200: sport\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_df['predicted_labels'] = predicted_labels"
      ],
      "metadata": {
        "id": "04vBu9_1jdZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tt2O2OrQjMmi",
        "outputId": "d5cef3b5-b0cf-470e-bbb2-612f8ea9189c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      category                                  short_description  \\\n",
              "7892    sports  youre 28 year old skating best ever life expla...   \n",
              "631     sports  really long journey embracing gender pair skat...   \n",
              "192   politics  democratic pennsylvania senate nominee found c...   \n",
              "5271      tech  facebook engineer fired allegedly selfidentify...   \n",
              "112   politics  two veteran new york democrat previously dodge...   \n",
              "\n",
              "     predicted_labels  \n",
              "7892            sport  \n",
              "631             sport  \n",
              "192          politics  \n",
              "5271             tech  \n",
              "112          politics  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba993afe-9dff-4269-b7c2-39ff7bc6b0c9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>short_description</th>\n",
              "      <th>predicted_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7892</th>\n",
              "      <td>sports</td>\n",
              "      <td>youre 28 year old skating best ever life expla...</td>\n",
              "      <td>sport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>631</th>\n",
              "      <td>sports</td>\n",
              "      <td>really long journey embracing gender pair skat...</td>\n",
              "      <td>sport</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>politics</td>\n",
              "      <td>democratic pennsylvania senate nominee found c...</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5271</th>\n",
              "      <td>tech</td>\n",
              "      <td>facebook engineer fired allegedly selfidentify...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>politics</td>\n",
              "      <td>two veteran new york democrat previously dodge...</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba993afe-9dff-4269-b7c2-39ff7bc6b0c9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ba993afe-9dff-4269-b7c2-39ff7bc6b0c9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ba993afe-9dff-4269-b7c2-39ff7bc6b0c9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assigning 'text_positive' column from df to y_true\n",
        "y_true = shuffled_df['category']\n",
        "\n",
        "# Assigning 'R_pos_count' column from merged to y_pred\n",
        "y_pred = shuffled_df['predicted_labels']\n",
        "\n",
        "# Calculating confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n"
      ],
      "metadata": {
        "id": "FOO57OJIjrFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtaining a score of how much do two data sets match \n",
        "total_obs = np.sum(cm)\n",
        "correct_classifications = np.diagonal(cm)\n",
        "match_rate = np.sum(correct_classifications) / total_obs\n",
        "print(match_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c024akJkj76h",
        "outputId": "7532cd06-7809-4926-a5b5-48e69e70df15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4791666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##BiLSTM + BERT \n"
      ],
      "metadata": {
        "id": "t6yPayWN3XlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install keras --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RnMSv1q48kE",
        "outputId": "4ad14786-8416-419e-b79b-f8585bf0a03f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['label'] = le.fit_transform(df['category'])\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ie6krjBX3Y9i",
        "outputId": "408d599c-c76c-469e-c3ff-8925c932e675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   category                                               text  \\\n",
              "0      tech  tv future in the hands of viewers with home th...   \n",
              "2     sport  tigers wary of farrell  gamble  leicester say ...   \n",
              "3     sport  yeading face newcastle in fa cup premiership s...   \n",
              "5  politics  howard hits back at mongrel jibe michael howar...   \n",
              "6  politics  blair prepares to name poll date tony blair is...   \n",
              "\n",
              "                                      tokenized_text  label  \n",
              "0  [tv, future, hand, viewer, home, theatre, syst...      2  \n",
              "2  [tiger, wary, farrell, gamble, leicester, say,...      1  \n",
              "3  [yeading, face, newcastle, fa, cup, premiershi...      1  \n",
              "5  [howard, hit, back, mongrel, jibe, michael, ho...      0  \n",
              "6  [blair, prepares, name, poll, date, tony, blai...      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b7b2b79-7fb3-4806-a8dc-c46bfa20d4dc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "      <th>tokenized_text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "      <td>[tv, future, hand, viewer, home, theatre, syst...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "      <td>[tiger, wary, farrell, gamble, leicester, say,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sport</td>\n",
              "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
              "      <td>[yeading, face, newcastle, fa, cup, premiershi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>politics</td>\n",
              "      <td>howard hits back at mongrel jibe michael howar...</td>\n",
              "      <td>[howard, hit, back, mongrel, jibe, michael, ho...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>politics</td>\n",
              "      <td>blair prepares to name poll date tony blair is...</td>\n",
              "      <td>[blair, prepares, name, poll, date, tony, blai...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b7b2b79-7fb3-4806-a8dc-c46bfa20d4dc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1b7b2b79-7fb3-4806-a8dc-c46bfa20d4dc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1b7b2b79-7fb3-4806-a8dc-c46bfa20d4dc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['label'].unique())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CFQMeeq8l69",
        "outputId": "bed42e29-0c07-41ed-a1f0-35e8e0c9bea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.iloc[:500]"
      ],
      "metadata": {
        "id": "lQ6fN9Km3h2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function generate_bert_embeddings takes a list of texts, a maximum sequence length, a tokenizer, and a BERT model as inputs. It encodes the texts using the tokenizer, truncates them if they exceed the maximum sequence length, pads them to the maximum sequence length, and generates embeddings using the BERT model. The embeddings are returned as a tensor."
      ],
      "metadata": {
        "id": "In47U8JLbOGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "def generate_bert_embeddings(texts, max_seq_length, tokenizer, model):\n",
        "    \"\"\"\n",
        "    Generates BERT embeddings for a list of texts using a given tokenizer and model.\n",
        "    Returns the embeddings as a tensor.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Encode the texts using the tokenizer and truncate if they exceed the maximum sequence length\n",
        "    encoded_texts = [tokenizer.encode(text, add_special_tokens=True, max_length=max_seq_length, truncation=True) for text in texts]\n",
        "    \n",
        "    # Pad the encoded texts to the maximum sequence length\n",
        "    padded_texts = pad_sequences(encoded_texts, maxlen=max_seq_length, padding='post', truncating='post')\n",
        "    \n",
        "    # Generate the embeddings using the BERT model\n",
        "    embeddings = model(padded_texts)[0]\n",
        "    \n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "mNFoGbmQ3lsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout, SpatialDropout1D, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "import numpy as np\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Load the BERT tokenizer and model\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Generate BERT embeddings for the texts\n",
        "max_seq_length = 100\n",
        "train_embeddings = generate_bert_embeddings(train_texts, max_seq_length, bert_tokenizer, bert_model)\n",
        "test_embeddings = generate_bert_embeddings(test_texts, max_seq_length, bert_tokenizer, bert_model)\n",
        "\n",
        "num_classes = len(set(train_labels))\n",
        "\n",
        "# Define the BiLSTM model architecture\n",
        "model = Sequential([\n",
        "    Bidirectional(LSTM(units=64, dropout=0.2, recurrent_dropout=0.2, input_shape=(max_seq_length, 768))),\n",
        "    Dense(units=32, activation='sigmoid'),\n",
        "    Dropout(0.2),\n",
        "    Dense(units=num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "#experimented with relu and sigmoid\n",
        "#relu generated an accuracy of about 93% whereas the sigmoid function yielded an accuracy of 97% so we keep that\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=1e-4), metrics=['accuracy'])\n",
        "#the learning rate seems to be optimal because we achieve similar accuracies on both our training, validation, and testing set. \n",
        "\n",
        "# Train the model\n",
        "batch_size = 32\n",
        "num_epochs = 10\n",
        "history = model.fit(train_embeddings, train_labels, batch_size=batch_size, epochs=num_epochs, validation_data=(test_embeddings, test_labels))\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "loss, accuracy = model.evaluate(test_embeddings, test_labels)\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2J-VANp3nt6",
        "outputId": "34766493-79ed-4593-a440-d8fc247ba1c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 14s 1s/step - loss: 1.1567 - accuracy: 0.3833 - val_loss: 0.7976 - val_accuracy: 0.7667\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 8s 904ms/step - loss: 0.6727 - accuracy: 0.8500 - val_loss: 0.4072 - val_accuracy: 0.9833\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 8s 1s/step - loss: 0.3464 - accuracy: 0.9750 - val_loss: 0.1904 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 8s 907ms/step - loss: 0.1919 - accuracy: 1.0000 - val_loss: 0.1300 - val_accuracy: 0.9833\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 7s 925ms/step - loss: 0.1262 - accuracy: 1.0000 - val_loss: 0.1092 - val_accuracy: 0.9833\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 8s 978ms/step - loss: 0.0979 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 8s 957ms/step - loss: 0.0808 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 0.9667\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 8s 986ms/step - loss: 0.0665 - accuracy: 1.0000 - val_loss: 0.0709 - val_accuracy: 0.9833\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 7s 885ms/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.0656 - val_accuracy: 0.9833\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 9s 1s/step - loss: 0.0550 - accuracy: 1.0000 - val_loss: 0.0778 - val_accuracy: 0.9833\n",
            "2/2 [==============================] - 0s 110ms/step - loss: 0.0778 - accuracy: 0.9833\n",
            "Test loss: 0.07784021645784378\n",
            "Test accuracy: 0.9833333492279053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('my_model.h5')"
      ],
      "metadata": {
        "id": "mm9lTGAB3t9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FoiH4M258Xh3",
        "outputId": "dd9df66e-949d-4822-84aa-42e8f1f973af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      category                                  short_description  \\\n",
              "7892    sports  youre 28 year old skating best ever life expla...   \n",
              "631     sports  really long journey embracing gender pair skat...   \n",
              "192   politics  democratic pennsylvania senate nominee found c...   \n",
              "5271      tech  facebook engineer fired allegedly selfidentify...   \n",
              "112   politics  two veteran new york democrat previously dodge...   \n",
              "\n",
              "                                         tokenized_text  label  \n",
              "7892  [youre, 28, year, old, skating, best, ever, li...      2  \n",
              "631   [really, long, journey, embracing, gender, pai...      2  \n",
              "192   [democratic, pennsylvania, senate, nominee, fo...      1  \n",
              "5271  [facebook, engineer, fired, allegedly, selfide...      0  \n",
              "112   [two, veteran, new, york, democrat, previously...      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-adab5b54-40b0-4feb-b4ca-c5fe3d9bc5ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>short_description</th>\n",
              "      <th>tokenized_text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7892</th>\n",
              "      <td>sports</td>\n",
              "      <td>youre 28 year old skating best ever life expla...</td>\n",
              "      <td>[youre, 28, year, old, skating, best, ever, li...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>631</th>\n",
              "      <td>sports</td>\n",
              "      <td>really long journey embracing gender pair skat...</td>\n",
              "      <td>[really, long, journey, embracing, gender, pai...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>politics</td>\n",
              "      <td>democratic pennsylvania senate nominee found c...</td>\n",
              "      <td>[democratic, pennsylvania, senate, nominee, fo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5271</th>\n",
              "      <td>tech</td>\n",
              "      <td>facebook engineer fired allegedly selfidentify...</td>\n",
              "      <td>[facebook, engineer, fired, allegedly, selfide...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>politics</td>\n",
              "      <td>two veteran new york democrat previously dodge...</td>\n",
              "      <td>[two, veteran, new, york, democrat, previously...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-adab5b54-40b0-4feb-b4ca-c5fe3d9bc5ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-adab5b54-40b0-4feb-b4ca-c5fe3d9bc5ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-adab5b54-40b0-4feb-b4ca-c5fe3d9bc5ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def label_categories(category):\n",
        "    if category == 'tech':\n",
        "        return 0\n",
        "    elif category == 'politics':\n",
        "        return 1\n",
        "    elif category == 'sports':\n",
        "        return 2"
      ],
      "metadata": {
        "id": "XuVkWlcu9NdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_df['label'] = shuffled_df['category'].apply(label_categories)"
      ],
      "metadata": {
        "id": "iCbZXtDZ8an8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "#bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "max_seq_length = 100\n",
        "df_subset = shuffled_df.head(100)\n",
        "\n",
        "df_subset['embeddings'] = df_subset['short_description'].apply(lambda x: generate_bert_embeddings([x], max_seq_length, bert_tokenizer, bert_model))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtSFIix6-Q81",
        "outputId": "80e22a05-694c-4ffb-df77-47ef9a981582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-119-9d0ff207077a>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_subset['embeddings'] = df_subset['short_description'].apply(lambda x: generate_bert_embeddings([x], max_seq_length, bert_tokenizer, bert_model))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the saved BiLSTM model\n",
        "bilstm_model = load_model('my_model.h5')\n",
        "\n",
        "# Apply the model to each embedding in the \"embeddings\" column\n",
        "df_subset['pred'] = df_subset['embeddings'].apply(lambda x: np.argmax(bilstm_model.predict(x), axis=-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyHvq7nwDRAN",
        "outputId": "c777ba3e-0ba6-4a9b-e3a1-66ad2d5a931b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 597ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 106ms/step\n",
            "1/1 [==============================] - 0s 411ms/step\n",
            "1/1 [==============================] - 1s 588ms/step\n",
            "1/1 [==============================] - 0s 485ms/step\n",
            "1/1 [==============================] - 1s 576ms/step\n",
            "1/1 [==============================] - 0s 203ms/step\n",
            "1/1 [==============================] - 0s 168ms/step\n",
            "1/1 [==============================] - 0s 188ms/step\n",
            "1/1 [==============================] - 0s 142ms/step\n",
            "1/1 [==============================] - 0s 181ms/step\n",
            "1/1 [==============================] - 0s 193ms/step\n",
            "1/1 [==============================] - 0s 170ms/step\n",
            "1/1 [==============================] - 0s 281ms/step\n",
            "1/1 [==============================] - 0s 248ms/step\n",
            "1/1 [==============================] - 0s 312ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 149ms/step\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-120-06f43d893693>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_subset['pred'] = df_subset['embeddings'].apply(lambda x: np.argmax(bilstm_model.predict(x), axis=-1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset = df_subset.drop('embeddings', axis=1)\n"
      ],
      "metadata": {
        "id": "B94KHFY4IR2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset.head(25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "id": "9wCU5mETXzEt",
        "outputId": "2c63132f-caf2-4357-8c8d-0b4e1c58d807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       category                                  short_description  \\\n",
              "7892     sports  youre 28 year old skating best ever life expla...   \n",
              "631      sports  really long journey embracing gender pair skat...   \n",
              "192    politics  democratic pennsylvania senate nominee found c...   \n",
              "5271       tech  facebook engineer fired allegedly selfidentify...   \n",
              "112    politics  two veteran new york democrat previously dodge...   \n",
              "7742     sports         kind given dont fall nbcs terry gannon say   \n",
              "598    politics  indiana state police investigating campus offi...   \n",
              "3980     sports                     fan hope last ring pick season   \n",
              "3463       tech  billionaire salesforce ceo denounced social me...   \n",
              "599      sports  everyone snowboard know missed grab im hiding ...   \n",
              "188      sports            anybody give st tell em charles said fk   \n",
              "85     politics  democrat cusp transforming paid leave child ca...   \n",
              "92     politics  senate gop leader cited candidate quality fact...   \n",
              "586      sports  twotime u olympic champion skier far failed wi...   \n",
              "445    politics   record number book racial lgbtq theme challenged   \n",
              "320    politics  mccarthy attorney argues letter committee issu...   \n",
              "15033      tech  man who claimed value diversity inclusion odd ...   \n",
              "32661      tech                                                big   \n",
              "541      sports  winter paralympics set open beijing russian at...   \n",
              "4525       tech  ntsb published preliminary report incident thu...   \n",
              "705    politics  texas republican past criticism u capitol riot...   \n",
              "24679      tech                thought would grow old die together   \n",
              "29434      tech  company issued massive recall report phone bat...   \n",
              "642    politics  josh mandel morgan harper running senate oppos...   \n",
              "205    politics  mean closely contested actually wisconsin pres...   \n",
              "\n",
              "                                          tokenized_text  label pred  \n",
              "7892   [youre, 28, year, old, skating, best, ever, li...      2  [2]  \n",
              "631    [really, long, journey, embracing, gender, pai...      2  [2]  \n",
              "192    [democratic, pennsylvania, senate, nominee, fo...      1  [2]  \n",
              "5271   [facebook, engineer, fired, allegedly, selfide...      0  [2]  \n",
              "112    [two, veteran, new, york, democrat, previously...      1  [2]  \n",
              "7742   [kind, given, dont, fall, nbcs, terry, gannon,...      2  [2]  \n",
              "598    [indiana, state, police, investigating, campus...      1  [2]  \n",
              "3980               [fan, hope, last, ring, pick, season]      2  [2]  \n",
              "3463   [billionaire, salesforce, ceo, denounced, soci...      0  [2]  \n",
              "599    [everyone, snowboard, know, missed, grab, im, ...      2  [2]  \n",
              "188     [anybody, give, st, tell, em, charles, said, fk]      2  [2]  \n",
              "85     [democrat, cusp, transforming, paid, leave, ch...      1  [2]  \n",
              "92     [senate, gop, leader, cited, candidate, qualit...      1  [0]  \n",
              "586    [twotime, u, olympic, champion, skier, far, fa...      2  [2]  \n",
              "445    [record, number, book, racial, lgbtq, theme, c...      1  [2]  \n",
              "320    [mccarthy, attorney, argues, letter, committee...      1  [2]  \n",
              "15033  [man, who, claimed, value, diversity, inclusio...      0  [2]  \n",
              "32661                                              [big]      0  [2]  \n",
              "541    [winter, paralympics, set, open, beijing, russ...      2  [2]  \n",
              "4525   [ntsb, published, preliminary, report, inciden...      0  [2]  \n",
              "705    [texas, republican, past, criticism, u, capito...      1  [0]  \n",
              "24679         [thought, would, grow, old, die, together]      0  [2]  \n",
              "29434  [company, issued, massive, recall, report, pho...      0  [2]  \n",
              "642    [josh, mandel, morgan, harper, running, senate...      1  [2]  \n",
              "205    [mean, closely, contested, actually, wisconsin...      1  [0]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd25836c-809b-4a31-912c-8edae11c278f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>short_description</th>\n",
              "      <th>tokenized_text</th>\n",
              "      <th>label</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7892</th>\n",
              "      <td>sports</td>\n",
              "      <td>youre 28 year old skating best ever life expla...</td>\n",
              "      <td>[youre, 28, year, old, skating, best, ever, li...</td>\n",
              "      <td>2</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>631</th>\n",
              "      <td>sports</td>\n",
              "      <td>really long journey embracing gender pair skat...</td>\n",
              "      <td>[really, long, journey, embracing, gender, pai...</td>\n",
              "      <td>2</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>politics</td>\n",
              "      <td>democratic pennsylvania senate nominee found c...</td>\n",
              "      <td>[democratic, pennsylvania, senate, nominee, fo...</td>\n",
              "      <td>1</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5271</th>\n",
              "      <td>tech</td>\n",
              "      <td>facebook engineer fired allegedly selfidentify...</td>\n",
              "      <td>[facebook, engineer, fired, allegedly, selfide...</td>\n",
              "      <td>0</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>politics</td>\n",
              "      <td>two veteran new york democrat previously dodge...</td>\n",
              "      <td>[two, veteran, new, york, democrat, previously...</td>\n",
              "      <td>1</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7742</th>\n",
              "      <td>sports</td>\n",
              "      <td>kind given dont fall nbcs terry gannon say</td>\n",
              "      <td>[kind, given, dont, fall, nbcs, terry, gannon,...</td>\n",
              "      <td>2</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>politics</td>\n",
              "      <td>indiana state police investigating campus offi...</td>\n",
              "      <td>[indiana, state, police, investigating, campus...</td>\n",
              "      <td>1</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3980</th>\n",
              "      <td>sports</td>\n",
              "      <td>fan hope last ring pick season</td>\n",
              "      <td>[fan, hope, last, ring, pick, season]</td>\n",
              "      <td>2</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3463</th>\n",
              "      <td>tech</td>\n",
              "      <td>billionaire salesforce ceo denounced social me...</td>\n",
              "      <td>[billionaire, salesforce, ceo, denounced, soci...</td>\n",
              "      <td>0</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>sports</td>\n",
              "      <td>everyone snowboard know missed grab im hiding ...</td>\n",
              "      <td>[everyone, snowboard, know, missed, grab, im, ...</td>\n",
              "      <td>2</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>sports</td>\n",
              "      <td>anybody give st tell em charles said fk</td>\n",
              "      <td>[anybody, give, st, tell, em, charles, said, fk]</td>\n",
              "      <td>2</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>politics</td>\n",
              "      <td>democrat cusp transforming paid leave child ca...</td>\n",
              "      <td>[democrat, cusp, transforming, paid, leave, ch...</td>\n",
              "      <td>1</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>politics</td>\n",
              "      <td>senate gop leader cited candidate quality fact...</td>\n",
              "      <td>[senate, gop, leader, cited, candidate, qualit...</td>\n",
              "      <td>1</td>\n",
              "      <td>[0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>586</th>\n",
              "      <td>sports</td>\n",
              "      <td>twotime u olympic champion skier far failed wi...</td>\n",
              "      <td>[twotime, u, olympic, champion, skier, far, fa...</td>\n",
              "      <td>2</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>445</th>\n",
              "      <td>politics</td>\n",
              "      <td>record number book racial lgbtq theme challenged</td>\n",
              "      <td>[record, number, book, racial, lgbtq, theme, c...</td>\n",
              "      <td>1</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>politics</td>\n",
              "      <td>mccarthy attorney argues letter committee issu...</td>\n",
              "      <td>[mccarthy, attorney, argues, letter, committee...</td>\n",
              "      <td>1</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15033</th>\n",
              "      <td>tech</td>\n",
              "      <td>man who claimed value diversity inclusion odd ...</td>\n",
              "      <td>[man, who, claimed, value, diversity, inclusio...</td>\n",
              "      <td>0</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32661</th>\n",
              "      <td>tech</td>\n",
              "      <td>big</td>\n",
              "      <td>[big]</td>\n",
              "      <td>0</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>541</th>\n",
              "      <td>sports</td>\n",
              "      <td>winter paralympics set open beijing russian at...</td>\n",
              "      <td>[winter, paralympics, set, open, beijing, russ...</td>\n",
              "      <td>2</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4525</th>\n",
              "      <td>tech</td>\n",
              "      <td>ntsb published preliminary report incident thu...</td>\n",
              "      <td>[ntsb, published, preliminary, report, inciden...</td>\n",
              "      <td>0</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>705</th>\n",
              "      <td>politics</td>\n",
              "      <td>texas republican past criticism u capitol riot...</td>\n",
              "      <td>[texas, republican, past, criticism, u, capito...</td>\n",
              "      <td>1</td>\n",
              "      <td>[0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24679</th>\n",
              "      <td>tech</td>\n",
              "      <td>thought would grow old die together</td>\n",
              "      <td>[thought, would, grow, old, die, together]</td>\n",
              "      <td>0</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29434</th>\n",
              "      <td>tech</td>\n",
              "      <td>company issued massive recall report phone bat...</td>\n",
              "      <td>[company, issued, massive, recall, report, pho...</td>\n",
              "      <td>0</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>642</th>\n",
              "      <td>politics</td>\n",
              "      <td>josh mandel morgan harper running senate oppos...</td>\n",
              "      <td>[josh, mandel, morgan, harper, running, senate...</td>\n",
              "      <td>1</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>politics</td>\n",
              "      <td>mean closely contested actually wisconsin pres...</td>\n",
              "      <td>[mean, closely, contested, actually, wisconsin...</td>\n",
              "      <td>1</td>\n",
              "      <td>[0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd25836c-809b-4a31-912c-8edae11c278f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bd25836c-809b-4a31-912c-8edae11c278f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bd25836c-809b-4a31-912c-8edae11c278f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Conclusion and Challanges"
      ],
      "metadata": {
        "id": "QkSRQKebbBQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Challenges: \n",
        "One of the primary challenges we faced when training our Bidirectional LSTM (BiLSTM) model was limited computational power. It is well-known that large datasets of several thousand examples are typically necessary for training BiLSTM models effectively for natural language processing tasks, such as text classification or sentiment analysis.\n",
        "\n",
        "Despite this recommendation, we were only able to use a small dataset of 300 articles due to computational constraints. This limited dataset resulted in a significant drop in model performance on new, unseen data compared to its performance on the validation and test sets. While the model achieved an accuracy of above 90% on the validation and test sets, its accuracy dropped to around 50% when evaluated on new data.\n",
        "\n",
        "Based on our analysis of the results, it appears that the poor performance of the model on new, unseen data can be attributed to overfitting. The small dataset size likely resulted in the model becoming too specialized to the training data, and as a result, was unable to generalize well to new data. \n",
        "\n",
        "We also ruled out any problems with biased datasets since we curated the dataset to be representative of different classes in equal amounts. \n",
        "\n",
        "To mitigate the overfitting issue, we attempted to experiment with different combinations of dropout rates and epoch sizes, but were unable to identify a set of hyperparameters that improved the model's performance. Consequently, we recommend that researchers and practitioners take into account the size of the dataset when training BiLSTM models, as a larger dataset is likely to yield more accurate results.\n",
        "\n",
        "In summary, while smaller datasets can still produce useful results, a sufficiently large dataset is recommended for training BiLSTM models to achieve optimal performance. This can help avoid the issue of overfitting and ensure that the model generalizes well to new, unseen data.\n"
      ],
      "metadata": {
        "id": "A6sDk6rEbBHa"
      }
    }
  ]
}